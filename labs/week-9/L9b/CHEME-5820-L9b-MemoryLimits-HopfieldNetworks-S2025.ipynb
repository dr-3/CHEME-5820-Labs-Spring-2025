{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5673760-2d3b-4530-9f08-9a8717e37ee6",
   "metadata": {},
   "source": [
    "# L9b: Introduction to Hopfield Networks\n",
    "In this lab, we are going to explore encoding and retriving multiple patterns using Hopfield Networks. In lecture, we considered only a single memory. In this lab, we expand the number of memories that we encode in the network. Does the retrival algorithm presented in `L9a` work for multiple memories?\n",
    "\n",
    "## Tasks\n",
    "Before we get started, let's first understand the Hopfield Network. Take a few minutes to review the background material on Hopfield Networks if you are not already familiar with them. Next, execute the `Run All Cells` command to check if you (or your neighbor) have any code or setup issues. Code issues, then raise your hands - and let's get those fixed!\n",
    "\n",
    "* __Task 1: Setup, Data, Constants (5 min)__: Let's take 5 minutes to load [the MINST handwritten digits dataset](https://en.wikipedia.org/wiki/MNIST_database) that our Hopfield network will memorize.\n",
    "*  __Task 2: Learn the Weights of the Network (5 min)__: In this task, we'll learn the weights of the Hopfield network from the training memories (images). A [Hopfield network](https://en.wikipedia.org/wiki/Hopfield_network) uses a special [Hebbian learning rule](chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://arxiv.org/pdf/2010.01472), where the weights $w_{ij}\\in\\mathbf{W}$ are _encoded_ by the image (or memory) the network is trying to learn.\n",
    "* __Task 3: Retrieve a memory from the network (30 min)__: In this task, we will retrieve a memory from the Hopfield network starting from a random state vector $\\mathbf{s}_{\\circ}$. We'll corrupt an image with random noise, and then see if the model recovers the correct memory given the corrputed starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468895f",
   "metadata": {},
   "source": [
    "## Background: What is a Hopfield network?\n",
    "A [Hopfield network](https://en.wikipedia.org/wiki/Hopfield_network) is a fully connected undirected graph \n",
    "consisting of $N$ nodes, where each node in the graph has a state $s = \\pm{1}$; each node is connected to every other node, but not to itself, i.e., the network has no self-loops. The weights of the connection between node $i$ and $j$, denoted as $w_{ij}\\in\\mathbf{W}$ are learned using [a Hebbian learning rule](https://en.wikipedia.org/wiki/Hebbian_theory). \n",
    "* _What is Hebbian learning?_ The [Hebbian learning rule](https://en.wikipedia.org/wiki/Hebbian_theory), proposed by [Donald Hebb in 1949](https://en.wikipedia.org/wiki/Donald_O._Hebb), says that synaptic connections between neurons are strengthened when they activate (fire) simultaneously, forming the biological basis for __associative learning__. This \"fire together, wire together\" principle underpins unsupervised learning in neural networks, linking co-active nodes to enable pattern storage and adaptation.\n",
    "* _How is this different from other learning approaches?_ Unlike the previous examples of learning, e.g., logistic regression, or any of the online learning approaches that we looked at previously, the parameters (weights) in a [Hopfield network](https://en.wikipedia.org/wiki/Hopfield_network) are entirely specified by the memories we want to encode. Thus, we do not need to search for weights or learn them by experimenting with the world. Instead, we can directly compute the weights from the memories we want to encode.\n",
    "\n",
    "### Encoding memories into a Hopfield network\n",
    "Suppose we wish our network to memorize $m$-images, where each image is an $n\\times{n}$ collection of black and white pixels represented as a vector $\\mathbf{s}_{i}\\in\\left\\{-1,1\\right\\}\\in{R}^{n^2}$. We encode the image using the following rule: if the pixel is white, we set the value to $1$, and if the pixel is black, we set the value to $-1$. Then, the weights that encode these $m$-images are given by:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\mathbf{W} = \\frac{1}{m}\\cdot\\sum_{i=1}^{m}\\mathbf{s}_{i}\\otimes\\mathbf{s}_{i}^{\\top}\n",
    "\\end{equation*}\n",
    "$$\n",
    "where $\\mathbf{s}_{i}$ denotes the state (pixels) of the image we want to memorize, and $\\otimes$ denotes the outer product. Thus, the weights are the average of all of our memories!\n",
    "\n",
    "* __How big is $m$?__: The maximum theoretical storage limit $K_{\\text{max}}$ (the maximum number of possible images that can be stored) of a Hopfield network, using the standard Hebbian learning rule, is approximately $K_{max}\\sim{0.138}{N}$, where $N$ is the number of neurons in the network. Thus, the network can reliably store about 14% of its size in patterns before retrieval errors become significant due to interference between stored patterns.\n",
    "\n",
    "Suppose we've encoded $m$ images and want to retrieve one of them. This seems magical. How does it work? \n",
    "\n",
    "### Memory retrieval\n",
    "The basic idea of [a Hopfield network](https://en.wikipedia.org/wiki/Hopfield_network) is that each memory is encoded as a _local minimum_ of a global energy function. Thus, during memory retrieval, when we supply a random state vector $\\hat{\\mathbf{s}}$, we will recover the _closet_ memory encoded in the network to where we start.\n",
    "The overall energy of the network is given by:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "E(\\mathbf{s}) = -\\frac{1}{2}\\cdot\\sum_{ij}w_{ij}s_{i}s_{j} - \\sum_{i}b_{i}s_{i}\n",
    "\\end{equation*}\n",
    "$$\n",
    "where $w_{ij}\\in\\mathbf{W}$ are the weights of the network, and $b_{i}$ is a bias term. The bias term is used to control the activation of the neurons in the network. The bias term is usually set to zero, but it can be used to control the activation threshold of the neurons in the network.\n",
    "\n",
    "#### Algorithm\n",
    "__Initialize__: Compute the weights $w_{ij}\\in\\mathbf{W}$ using the Hebbian learning rule, as described above.  Initialize the network with a random state $\\mathbf{s}$. Then, use the following algorithm to retrieve a memory:\n",
    "\n",
    "While __not__ converged:\n",
    "1. Compute the energy of the network in the current state $\\mathbf{s}$ before the update: $E(\\mathbf{s})$.\n",
    "1. Asynchronous update. Choose a random node $i$ and compute a new (potential) state $s_{i}^{\\prime}$ using the update rule: $s_{i}^{\\prime} \\leftarrow \\sigma\\left(\\sum_{j}w_{ij}s_{j}-b_{i}\\right)$, where $\\sigma$ is [the `sign(...)` function](https://docs.julialang.org/en/v1/base/math/#Base.sign) and $b_{i}$ is a bias (threshold) parameter.  \n",
    "2. Compute the energy of the network after the update: $E(\\mathbf{s}^{\\prime})$. Update the state of the network: $\\mathbf{s} \\leftarrow \\mathbf{s}^{\\prime}$.\n",
    "3. Check for convergence: if the change in the energy of the network is small $(E(\\mathbf{s}^{\\prime}) - E(\\mathbf{s}))^{2} \\leq\\epsilon$ and we have hit the minimum number of iterations (visited each pixel on average $n$ times), then we have converged.\n",
    "4. Continue until convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b0615a",
   "metadata": {},
   "source": [
    "## Task 1: Setup, Data, and Prerequisites\n",
    "We set up the computational environment by including the `Include.jl` file, loading any needed resources, such as sample datasets, and setting up any required constants. \n",
    "* The `Include.jl` file also loads external packages, various functions that we will use in the exercise, and custom types to model the components of our problem. It checks for a `Manifest.toml` file; if it finds one, packages are loaded. Other packages are downloaded and then loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414aa20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `C:\\Users\\danie\\CHEME5820\\CHEME-5820-Labs-Spring-2025\\labs\\week-9\\L9b`\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StaticArrays ─────── v1.9.13\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Static ───────────── v1.2.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m OneHotArrays ─────── v0.2.6\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Setfield ─────────── v1.1.2\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Polynomials ──────── v4.0.19\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m XTermColors ──────── v0.2.1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m KernelAbstractions ─ v0.9.34\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m NNlib ────────────── v0.9.28\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m UnsafeAtomics ────── v0.3.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ImageInTerminal ──── v0.5.4\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Atomix ───────────── v1.1.1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m GPUArraysCore ────── v0.2.0\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\danie\\CHEME5820\\CHEME-5820-Labs-Spring-2025\\labs\\week-9\\L9b\\Project.toml`\n",
      "  \u001b[90m[5ae59095] \u001b[39m\u001b[92m+ Colors v0.13.0\u001b[39m\n",
      "  \u001b[90m[b4f34e82] \u001b[39m\u001b[92m+ Distances v0.10.12\u001b[39m\n",
      "  \u001b[90m[5789e2e9] \u001b[39m\u001b[92m+ FileIO v1.17.0\u001b[39m\n",
      "  \u001b[90m[82e4d734] \u001b[39m\u001b[92m+ ImageIO v0.6.9\u001b[39m\n",
      "  \u001b[90m[d8c32880] \u001b[39m\u001b[92m+ ImageInTerminal v0.5.4\u001b[39m\n",
      "  \u001b[90m[916415d5] \u001b[39m\u001b[92m+ Images v0.26.2\u001b[39m\n",
      "  \u001b[90m[033835bb] \u001b[39m\u001b[92m+ JLD2 v0.5.11\u001b[39m\n",
      "  \u001b[90m[0b1bfda6] \u001b[39m\u001b[92m+ OneHotArrays v0.2.6\u001b[39m\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[91a5bcdd] \u001b[39m\u001b[92m+ Plots v1.40.7\u001b[39m\n",
      "  \u001b[90m[10745b16] \u001b[39m\u001b[92m+ Statistics v1.11.1\u001b[39m\n",
      "  \u001b[90m[37e2e46d] \u001b[39m\u001b[93m~ LinearAlgebra ⇒ v1.11.0\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\danie\\CHEME5820\\CHEME-5820-Labs-Spring-2025\\labs\\week-9\\L9b\\Manifest.toml`\n",
      "  \u001b[90m[621f4979] \u001b[39m\u001b[92m+ AbstractFFTs v1.5.0\u001b[39m\n",
      "  \u001b[90m[79e6a3ab] \u001b[39m\u001b[92m+ Adapt v4.2.0\u001b[39m\n",
      "  \u001b[90m[66dad0bd] \u001b[39m\u001b[92m+ AliasTables v1.1.3\u001b[39m\n",
      "  \u001b[90m[ec485272] \u001b[39m\u001b[92m+ ArnoldiMethod v0.4.0\u001b[39m\n",
      "  \u001b[90m[4fba245c] \u001b[39m\u001b[92m+ ArrayInterface v7.18.0\u001b[39m\n",
      "  \u001b[90m[a9b6321e] \u001b[39m\u001b[92m+ Atomix v1.1.1\u001b[39m\n",
      "  \u001b[90m[13072b0f] \u001b[39m\u001b[92m+ AxisAlgorithms v1.1.0\u001b[39m\n",
      "  \u001b[90m[39de3d68] \u001b[39m\u001b[92m+ AxisArrays v0.4.7\u001b[39m\n",
      "  \u001b[90m[d1d4a3ce] \u001b[39m\u001b[92m+ BitFlags v0.1.9\u001b[39m\n",
      "  \u001b[90m[62783981] \u001b[39m\u001b[92m+ BitTwiddlingConvenienceFunctions v0.1.6\u001b[39m\n",
      "  \u001b[90m[fa961155] \u001b[39m\u001b[92m+ CEnum v0.5.0\u001b[39m\n",
      "  \u001b[90m[2a0fbf3d] \u001b[39m\u001b[92m+ CPUSummary v0.2.6\u001b[39m\n",
      "  \u001b[90m[aafaddc9] \u001b[39m\u001b[92m+ CatIndices v0.2.2\u001b[39m\n",
      "  \u001b[90m[d360d2e6] \u001b[39m\u001b[92m+ ChainRulesCore v1.25.1\u001b[39m\n",
      "  \u001b[90m[fb6a15b2] \u001b[39m\u001b[92m+ CloseOpenIntervals v0.1.13\u001b[39m\n",
      "  \u001b[90m[aaaa29a8] \u001b[39m\u001b[92m+ Clustering v0.15.8\u001b[39m\n",
      "  \u001b[90m[944b1d66] \u001b[39m\u001b[92m+ CodecZlib v0.7.8\u001b[39m\n",
      "  \u001b[90m[35d6a980] \u001b[39m\u001b[92m+ ColorSchemes v3.29.0\u001b[39m\n",
      "  \u001b[90m[3da002f7] \u001b[39m\u001b[92m+ ColorTypes v0.12.0\u001b[39m\n",
      "  \u001b[90m[c3611d14] \u001b[39m\u001b[92m+ ColorVectorSpace v0.11.0\u001b[39m\n",
      "  \u001b[90m[5ae59095] \u001b[39m\u001b[92m+ Colors v0.13.0\u001b[39m\n",
      "  \u001b[90m[f70d9fcc] \u001b[39m\u001b[92m+ CommonWorldInvalidations v1.0.0\u001b[39m\n",
      "  \u001b[90m[34da2185] \u001b[39m\u001b[92m+ Compat v4.16.0\u001b[39m\n",
      "  \u001b[90m[ed09eef8] \u001b[39m\u001b[92m+ ComputationalResources v0.3.2\u001b[39m\n",
      "  \u001b[90m[f0e56b4a] \u001b[39m\u001b[92m+ ConcurrentUtilities v2.5.0\u001b[39m\n",
      "  \u001b[90m[187b0558] \u001b[39m\u001b[92m+ ConstructionBase v1.5.8\u001b[39m\n",
      "  \u001b[90m[d38c429a] \u001b[39m\u001b[92m+ Contour v0.6.3\u001b[39m\n",
      "  \u001b[90m[150eb455] \u001b[39m\u001b[92m+ CoordinateTransformations v0.6.4\u001b[39m\n",
      "  \u001b[90m[adafc99b] \u001b[39m\u001b[92m+ CpuId v0.3.1\u001b[39m\n",
      "  \u001b[90m[a8cc5b0e] \u001b[39m\u001b[92m+ Crayons v4.1.1\u001b[39m\n",
      "  \u001b[90m[dc8bdbbb] \u001b[39m\u001b[92m+ CustomUnitRanges v1.0.2\u001b[39m\n",
      "  \u001b[90m[9a962f9c] \u001b[39m\u001b[92m+ DataAPI v1.16.0\u001b[39m\n",
      "  \u001b[90m[864edb3b] \u001b[39m\u001b[92m+ DataStructures v0.18.20\u001b[39m\n",
      "  \u001b[90m[8bb1440f] \u001b[39m\u001b[92m+ DelimitedFiles v1.9.1\u001b[39m\n",
      "  \u001b[90m[b4f34e82] \u001b[39m\u001b[92m+ Distances v0.10.12\u001b[39m\n",
      "  \u001b[90m[ffbed154] \u001b[39m\u001b[92m+ DocStringExtensions v0.9.3\u001b[39m\n",
      "  \u001b[90m[460bff9d] \u001b[39m\u001b[92m+ ExceptionUnwrapping v0.1.11\u001b[39m\n",
      "  \u001b[90m[c87230d0] \u001b[39m\u001b[92m+ FFMPEG v0.4.2\u001b[39m\n",
      "  \u001b[90m[4f61f5a4] \u001b[39m\u001b[92m+ FFTViews v0.3.2\u001b[39m\n",
      "  \u001b[90m[7a1cc6ca] \u001b[39m\u001b[92m+ FFTW v1.8.1\u001b[39m\n",
      "  \u001b[90m[5789e2e9] \u001b[39m\u001b[92m+ FileIO v1.17.0\u001b[39m\n",
      "  \u001b[90m[53c48c17] \u001b[39m\u001b[92m+ FixedPointNumbers v0.8.5\u001b[39m\n",
      "  \u001b[90m[1fa38f19] \u001b[39m\u001b[92m+ Format v1.3.7\u001b[39m\n",
      "  \u001b[90m[46192b85] \u001b[39m\u001b[92m+ GPUArraysCore v0.2.0\u001b[39m\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[28b8d3ca] \u001b[39m\u001b[92m+ GR v0.72.8\u001b[39m\n",
      "  \u001b[90m[a2bd30eb] \u001b[39m\u001b[92m+ Graphics v1.1.3\u001b[39m\n",
      "  \u001b[90m[86223c79] \u001b[39m\u001b[92m+ Graphs v1.12.0\u001b[39m\n",
      "  \u001b[90m[42e2da0e] \u001b[39m\u001b[92m+ Grisu v1.0.2\u001b[39m\n",
      "  \u001b[90m[cd3eb016] \u001b[39m\u001b[92m+ HTTP v1.10.15\u001b[39m\n",
      "  \u001b[90m[2c695a8d] \u001b[39m\u001b[92m+ HistogramThresholding v0.3.1\u001b[39m\n",
      "  \u001b[90m[3e5b6fbb] \u001b[39m\u001b[92m+ HostCPUFeatures v0.1.17\u001b[39m\n",
      "  \u001b[90m[615f187c] \u001b[39m\u001b[92m+ IfElse v0.1.1\u001b[39m\n",
      "  \u001b[90m[2803e5a7] \u001b[39m\u001b[92m+ ImageAxes v0.6.12\u001b[39m\n",
      "  \u001b[90m[c817782e] \u001b[39m\u001b[92m+ ImageBase v0.1.7\u001b[39m\n",
      "  \u001b[90m[cbc4b850] \u001b[39m\u001b[92m+ ImageBinarization v0.3.1\u001b[39m\n",
      "  \u001b[90m[f332f351] \u001b[39m\u001b[92m+ ImageContrastAdjustment v0.3.12\u001b[39m\n",
      "  \u001b[90m[a09fc81d] \u001b[39m\u001b[92m+ ImageCore v0.10.5\u001b[39m\n",
      "  \u001b[90m[89d5987c] \u001b[39m\u001b[92m+ ImageCorners v0.1.3\u001b[39m\n",
      "  \u001b[90m[51556ac3] \u001b[39m\u001b[92m+ ImageDistances v0.2.17\u001b[39m\n",
      "  \u001b[90m[6a3955dd] \u001b[39m\u001b[92m+ ImageFiltering v0.7.9\u001b[39m\n",
      "  \u001b[90m[82e4d734] \u001b[39m\u001b[92m+ ImageIO v0.6.9\u001b[39m\n",
      "  \u001b[90m[d8c32880] \u001b[39m\u001b[92m+ ImageInTerminal v0.5.4\u001b[39m\n",
      "  \u001b[90m[6218d12a] \u001b[39m\u001b[92m+ ImageMagick v1.4.0\u001b[39m\n",
      "  \u001b[90m[bc367c6b] \u001b[39m\u001b[92m+ ImageMetadata v0.9.10\u001b[39m\n",
      "  \u001b[90m[787d08f9] \u001b[39m\u001b[92m+ ImageMorphology v0.4.5\u001b[39m\n",
      "  \u001b[90m[2996bd0c] \u001b[39m\u001b[92m+ ImageQualityIndexes v0.3.7\u001b[39m\n",
      "  \u001b[90m[80713f31] \u001b[39m\u001b[92m+ ImageSegmentation v1.8.4\u001b[39m\n",
      "  \u001b[90m[4e3cecfd] \u001b[39m\u001b[92m+ ImageShow v0.3.8\u001b[39m\n",
      "  \u001b[90m[02fcd773] \u001b[39m\u001b[92m+ ImageTransformations v0.10.1\u001b[39m\n",
      "  \u001b[90m[916415d5] \u001b[39m\u001b[92m+ Images v0.26.2\u001b[39m\n",
      "  \u001b[90m[9b13fd28] \u001b[39m\u001b[92m+ IndirectArrays v1.0.0\u001b[39m\n",
      "  \u001b[90m[d25df0c9] \u001b[39m\u001b[92m+ Inflate v0.1.5\u001b[39m\n",
      "  \u001b[90m[1d092043] \u001b[39m\u001b[92m+ IntegralArrays v0.1.6\u001b[39m\n",
      "  \u001b[90m[a98d9a8b] \u001b[39m\u001b[92m+ Interpolations v0.15.1\u001b[39m\n",
      "  \u001b[90m[8197267c] \u001b[39m\u001b[92m+ IntervalSets v0.7.10\u001b[39m\n",
      "  \u001b[90m[92d709cd] \u001b[39m\u001b[92m+ IrrationalConstants v0.2.4\u001b[39m\n",
      "  \u001b[90m[c8e1da08] \u001b[39m\u001b[92m+ IterTools v1.10.0\u001b[39m\n",
      "  \u001b[90m[033835bb] \u001b[39m\u001b[92m+ JLD2 v0.5.11\u001b[39m\n",
      "  \u001b[90m[1019f520] \u001b[39m\u001b[92m+ JLFzf v0.1.9\u001b[39m\n",
      "  \u001b[90m[692b3bcd] \u001b[39m\u001b[92m+ JLLWrappers v1.7.0\u001b[39m\n",
      "  \u001b[90m[682c06a0] \u001b[39m\u001b[92m+ JSON v0.21.4\u001b[39m\n",
      "  \u001b[90m[b835a17e] \u001b[39m\u001b[92m+ JpegTurbo v0.1.5\u001b[39m\n",
      "  \u001b[90m[63c18a36] \u001b[39m\u001b[92m+ KernelAbstractions v0.9.34\u001b[39m\n",
      "  \u001b[90m[b964fa9f] \u001b[39m\u001b[92m+ LaTeXStrings v1.4.0\u001b[39m\n",
      "  \u001b[90m[23fbe1c1] \u001b[39m\u001b[92m+ Latexify v0.16.6\u001b[39m\n",
      "  \u001b[90m[10f19ff3] \u001b[39m\u001b[92m+ LayoutPointers v0.1.17\u001b[39m\n",
      "  \u001b[90m[8cdb02fc] \u001b[39m\u001b[92m+ LazyModules v0.3.1\u001b[39m\n",
      "  \u001b[90m[2ab3a3ac] \u001b[39m\u001b[92m+ LogExpFunctions v0.3.29\u001b[39m\n",
      "  \u001b[90m[e6f89c97] \u001b[39m\u001b[92m+ LoggingExtras v1.1.0\u001b[39m\n",
      "  \u001b[90m[bdcacae8] \u001b[39m\u001b[92m+ LoopVectorization v0.12.171\u001b[39m\n",
      "  \u001b[90m[1914dd2f] \u001b[39m\u001b[92m+ MacroTools v0.5.15\u001b[39m\n",
      "  \u001b[90m[d125e4d3] \u001b[39m\u001b[92m+ ManualMemory v0.1.8\u001b[39m\n",
      "  \u001b[90m[dbb5928d] \u001b[39m\u001b[92m+ MappedArrays v0.4.2\u001b[39m\n",
      "  \u001b[90m[739be429] \u001b[39m\u001b[92m+ MbedTLS v1.1.9\u001b[39m\n",
      "  \u001b[90m[442fdcdd] \u001b[39m\u001b[92m+ Measures v0.3.2\u001b[39m\n",
      "  \u001b[90m[626554b9] \u001b[39m\u001b[92m+ MetaGraphs v0.8.0\u001b[39m\n",
      "  \u001b[90m[e1d29d7a] \u001b[39m\u001b[92m+ Missings v1.2.0\u001b[39m\n",
      "  \u001b[90m[e94cdb99] \u001b[39m\u001b[92m+ MosaicViews v0.3.4\u001b[39m\n",
      "  \u001b[90m[872c559c] \u001b[39m\u001b[92m+ NNlib v0.9.28\u001b[39m\n",
      "  \u001b[90m[77ba4419] \u001b[39m\u001b[92m+ NaNMath v1.1.2\u001b[39m\n",
      "  \u001b[90m[b8a86587] \u001b[39m\u001b[92m+ NearestNeighbors v0.4.21\u001b[39m\n",
      "  \u001b[90m[f09324ee] \u001b[39m\u001b[92m+ Netpbm v1.1.1\u001b[39m\n",
      "  \u001b[90m[6fe1bfb0] \u001b[39m\u001b[92m+ OffsetArrays v1.15.0\u001b[39m\n",
      "  \u001b[90m[0b1bfda6] \u001b[39m\u001b[92m+ OneHotArrays v0.2.6\u001b[39m\n",
      "  \u001b[90m[52e1d378] \u001b[39m\u001b[92m+ OpenEXR v0.3.3\u001b[39m\n",
      "  \u001b[90m[4d8831e6] \u001b[39m\u001b[92m+ OpenSSL v1.4.3\u001b[39m\n",
      "  \u001b[90m[bac558e1] \u001b[39m\u001b[92m+ OrderedCollections v1.8.0\u001b[39m\n",
      "  \u001b[90m[f57f5aa1] \u001b[39m\u001b[92m+ PNGFiles v0.4.4\u001b[39m\n",
      "  \u001b[90m[5432bcbf] \u001b[39m\u001b[92m+ PaddedViews v0.5.12\u001b[39m\n",
      "  \u001b[90m[d96e819e] \u001b[39m\u001b[92m+ Parameters v0.12.3\u001b[39m\n",
      "  \u001b[90m[69de0a69] \u001b[39m\u001b[92m+ Parsers v2.8.1\u001b[39m\n",
      "  \u001b[90m[b98c9c47] \u001b[39m\u001b[92m+ Pipe v1.3.0\u001b[39m\n",
      "  \u001b[90m[eebad327] \u001b[39m\u001b[92m+ PkgVersion v0.3.3\u001b[39m\n",
      "  \u001b[90m[ccf2f8ad] \u001b[39m\u001b[92m+ PlotThemes v3.3.0\u001b[39m\n",
      "  \u001b[90m[995b91a9] \u001b[39m\u001b[92m+ PlotUtils v1.4.3\u001b[39m\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[91a5bcdd] \u001b[39m\u001b[92m+ Plots v1.40.7\u001b[39m\n",
      "  \u001b[90m[1d0040c9] \u001b[39m\u001b[92m+ PolyesterWeave v0.2.2\u001b[39m\n",
      "  \u001b[90m[f27b6e38] \u001b[39m\u001b[92m+ Polynomials v4.0.19\u001b[39m\n",
      "  \u001b[90m[aea7be01] \u001b[39m\u001b[92m+ PrecompileTools v1.2.1\u001b[39m\n",
      "  \u001b[90m[21216c6a] \u001b[39m\u001b[92m+ Preferences v1.4.3\u001b[39m\n",
      "  \u001b[90m[92933f4c] \u001b[39m\u001b[92m+ ProgressMeter v1.10.2\u001b[39m\n",
      "  \u001b[90m[43287f4e] \u001b[39m\u001b[92m+ PtrArrays v1.3.0\u001b[39m\n",
      "  \u001b[90m[4b34888f] \u001b[39m\u001b[92m+ QOI v1.0.1\u001b[39m\n",
      "  \u001b[90m[94ee1d12] \u001b[39m\u001b[92m+ Quaternions v0.7.6\u001b[39m\n",
      "  \u001b[90m[b3c3ace0] \u001b[39m\u001b[92m+ RangeArrays v0.3.2\u001b[39m\n",
      "  \u001b[90m[c84ed2f1] \u001b[39m\u001b[92m+ Ratios v0.4.5\u001b[39m\n",
      "  \u001b[90m[c1ae055f] \u001b[39m\u001b[92m+ RealDot v0.1.0\u001b[39m\n",
      "  \u001b[90m[3cdcf5f2] \u001b[39m\u001b[92m+ RecipesBase v1.3.4\u001b[39m\n",
      "  \u001b[90m[01d81517] \u001b[39m\u001b[92m+ RecipesPipeline v0.6.12\u001b[39m\n",
      "  \u001b[90m[189a3867] \u001b[39m\u001b[92m+ Reexport v1.2.2\u001b[39m\n",
      "  \u001b[90m[dee08c22] \u001b[39m\u001b[92m+ RegionTrees v0.3.2\u001b[39m\n",
      "  \u001b[90m[05181044] \u001b[39m\u001b[92m+ RelocatableFolders v1.0.1\u001b[39m\n",
      "  \u001b[90m[ae029012] \u001b[39m\u001b[92m+ Requires v1.3.1\u001b[39m\n",
      "  \u001b[90m[6038ab10] \u001b[39m\u001b[92m+ Rotations v1.7.1\u001b[39m\n",
      "  \u001b[90m[fdea26ae] \u001b[39m\u001b[92m+ SIMD v3.7.1\u001b[39m\n",
      "  \u001b[90m[94e857df] \u001b[39m\u001b[92m+ SIMDTypes v0.1.0\u001b[39m\n",
      "  \u001b[90m[476501e8] \u001b[39m\u001b[92m+ SLEEFPirates v0.6.43\u001b[39m\n",
      "  \u001b[90m[6c6a2e73] \u001b[39m\u001b[92m+ Scratch v1.2.1\u001b[39m\n",
      "  \u001b[90m[efcf1570] \u001b[39m\u001b[92m+ Setfield v1.1.2\u001b[39m\n",
      "  \u001b[90m[992d4aef] \u001b[39m\u001b[92m+ Showoff v1.0.3\u001b[39m\n",
      "  \u001b[90m[777ac1f9] \u001b[39m\u001b[92m+ SimpleBufferStream v1.2.0\u001b[39m\n",
      "  \u001b[90m[699a6c99] \u001b[39m\u001b[92m+ SimpleTraits v0.9.4\u001b[39m\n",
      "  \u001b[90m[47aef6b3] \u001b[39m\u001b[92m+ SimpleWeightedGraphs v1.4.0\u001b[39m\n",
      "  \u001b[90m[45858cf5] \u001b[39m\u001b[92m+ Sixel v0.1.3\u001b[39m\n",
      "  \u001b[90m[a2af1166] \u001b[39m\u001b[92m+ SortingAlgorithms v1.2.1\u001b[39m\n",
      "  \u001b[90m[860ef19b] \u001b[39m\u001b[92m+ StableRNGs v1.0.2\u001b[39m\n",
      "  \u001b[90m[cae243ae] \u001b[39m\u001b[92m+ StackViews v0.1.1\u001b[39m\n",
      "  \u001b[90m[aedffcd0] \u001b[39m\u001b[92m+ Static v1.2.0\u001b[39m\n",
      "  \u001b[90m[0d7ed370] \u001b[39m\u001b[92m+ StaticArrayInterface v1.8.0\u001b[39m\n",
      "  \u001b[90m[90137ffa] \u001b[39m\u001b[92m+ StaticArrays v1.9.13\u001b[39m\n",
      "  \u001b[90m[1e83bf80] \u001b[39m\u001b[92m+ StaticArraysCore v1.4.3\u001b[39m\n",
      "  \u001b[90m[10745b16] \u001b[39m\u001b[92m+ Statistics v1.11.1\u001b[39m\n",
      "  \u001b[90m[82ae8749] \u001b[39m\u001b[92m+ StatsAPI v1.7.0\u001b[39m\n",
      "  \u001b[90m[2913bbd2] \u001b[39m\u001b[92m+ StatsBase v0.34.4\u001b[39m\n",
      "  \u001b[90m[62fd8b95] \u001b[39m\u001b[92m+ TensorCore v0.1.1\u001b[39m\n",
      "  \u001b[90m[8290d209] \u001b[39m\u001b[92m+ ThreadingUtilities v0.5.2\u001b[39m\n",
      "  \u001b[90m[731e570b] \u001b[39m\u001b[92m+ TiffImages v0.11.3\u001b[39m\n",
      "  \u001b[90m[06e1c1a7] \u001b[39m\u001b[92m+ TiledIteration v0.5.0\u001b[39m\n",
      "  \u001b[90m[3bb67fe8] \u001b[39m\u001b[92m+ TranscodingStreams v0.11.3\u001b[39m\n",
      "  \u001b[90m[5c2747f8] \u001b[39m\u001b[92m+ URIs v1.5.1\u001b[39m\n",
      "  \u001b[90m[3a884ed6] \u001b[39m\u001b[92m+ UnPack v1.0.2\u001b[39m\n",
      "  \u001b[90m[1cfade01] \u001b[39m\u001b[92m+ UnicodeFun v0.4.1\u001b[39m\n",
      "  \u001b[90m[1986cc42] \u001b[39m\u001b[92m+ Unitful v1.22.0\u001b[39m\n",
      "  \u001b[90m[45397f5d] \u001b[39m\u001b[92m+ UnitfulLatexify v1.6.4\u001b[39m\n",
      "  \u001b[90m[013be700] \u001b[39m\u001b[92m+ UnsafeAtomics v0.3.0\u001b[39m\n",
      "  \u001b[90m[41fe7b60] \u001b[39m\u001b[92m+ Unzip v0.2.0\u001b[39m\n",
      "  \u001b[90m[3d5dd08c] \u001b[39m\u001b[92m+ VectorizationBase v0.21.71\u001b[39m\n",
      "  \u001b[90m[e3aaa7dc] \u001b[39m\u001b[92m+ WebP v0.1.3\u001b[39m\n",
      "  \u001b[90m[efce3f68] \u001b[39m\u001b[92m+ WoodburyMatrices v1.0.0\u001b[39m\n",
      "  \u001b[90m[c8c2cc18] \u001b[39m\u001b[92m+ XTermColors v0.2.1\u001b[39m\n",
      "  \u001b[90m[6e34b625] \u001b[39m\u001b[92m+ Bzip2_jll v1.0.9+0\u001b[39m\n",
      "  \u001b[90m[83423d85] \u001b[39m\u001b[92m+ Cairo_jll v1.18.2+1\u001b[39m\n",
      "  \u001b[90m[ee1fde0b] \u001b[39m\u001b[92m+ Dbus_jll v1.14.10+0\u001b[39m\n",
      "  \u001b[90m[2702e6a9] \u001b[39m\u001b[92m+ EpollShim_jll v0.0.20230411+1\u001b[39m\n",
      "  \u001b[90m[2e619515] \u001b[39m\u001b[92m+ Expat_jll v2.6.5+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[b22a6f82] \u001b[39m\u001b[92m+ FFMPEG_jll v4.4.2+2\u001b[39m\n",
      "  \u001b[90m[f5851436] \u001b[39m\u001b[92m+ FFTW_jll v3.3.10+3\u001b[39m\n",
      "  \u001b[90m[a3f928ae] \u001b[39m\u001b[92m+ Fontconfig_jll v2.15.0+0\u001b[39m\n",
      "  \u001b[90m[d7e528f0] \u001b[39m\u001b[92m+ FreeType2_jll v2.13.3+1\u001b[39m\n",
      "  \u001b[90m[559328eb] \u001b[39m\u001b[92m+ FriBidi_jll v1.0.16+0\u001b[39m\n",
      "  \u001b[90m[0656b61e] \u001b[39m\u001b[92m+ GLFW_jll v3.4.0+2\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[d2c73de3] \u001b[39m\u001b[92m+ GR_jll v0.72.8+0\u001b[39m\n",
      "  \u001b[90m[78b55507] \u001b[39m\u001b[92m+ Gettext_jll v0.21.0+0\u001b[39m\n",
      "  \u001b[90m[61579ee1] \u001b[39m\u001b[92m+ Ghostscript_jll v9.55.0+4\u001b[39m\n",
      "  \u001b[90m[59f7168a] \u001b[39m\u001b[92m+ Giflib_jll v5.2.3+0\u001b[39m\n",
      "  \u001b[90m[7746bdde] \u001b[39m\u001b[92m+ Glib_jll v2.82.4+0\u001b[39m\n",
      "  \u001b[90m[3b182d85] \u001b[39m\u001b[92m+ Graphite2_jll v1.3.14+1\u001b[39m\n",
      "  \u001b[90m[2e76f6c2] \u001b[39m\u001b[92m+ HarfBuzz_jll v8.5.0+0\u001b[39m\n",
      "  \u001b[90m[c73af94c] \u001b[39m\u001b[92m+ ImageMagick_jll v7.1.1+1\u001b[39m\n",
      "  \u001b[90m[905a6f67] \u001b[39m\u001b[92m+ Imath_jll v3.1.11+0\u001b[39m\n",
      "  \u001b[90m[1d5cc7b8] \u001b[39m\u001b[92m+ IntelOpenMP_jll v2025.0.4+0\u001b[39m\n",
      "  \u001b[90m[aacddb02] \u001b[39m\u001b[92m+ JpegTurbo_jll v3.1.1+0\u001b[39m\n",
      "  \u001b[90m[c1c5ebd0] \u001b[39m\u001b[92m+ LAME_jll v3.100.2+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[88015f11] \u001b[39m\u001b[92m+ LERC_jll v3.0.0+1\u001b[39m\n",
      "  \u001b[90m[1d63c593] \u001b[39m\u001b[92m+ LLVMOpenMP_jll v18.1.7+0\u001b[39m\n",
      "  \u001b[90m[dd4b983a] \u001b[39m\u001b[92m+ LZO_jll v2.10.3+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[e9f186c6] \u001b[39m\u001b[92m+ Libffi_jll v3.2.2+2\u001b[39m\n",
      "  \u001b[90m[d4300ac3] \u001b[39m\u001b[92m+ Libgcrypt_jll v1.11.0+0\u001b[39m\n",
      "  \u001b[90m[7e76a0d4] \u001b[39m\u001b[92m+ Libglvnd_jll v1.7.0+0\u001b[39m\n",
      "  \u001b[90m[7add5ba3] \u001b[39m\u001b[92m+ Libgpg_error_jll v1.51.1+0\u001b[39m\n",
      "  \u001b[90m[94ce4f54] \u001b[39m\u001b[92m+ Libiconv_jll v1.18.0+0\u001b[39m\n",
      "  \u001b[90m[4b2f31a3] \u001b[39m\u001b[92m+ Libmount_jll v2.40.3+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[89763e89] \u001b[39m\u001b[92m+ Libtiff_jll v4.4.0+0\u001b[39m\n",
      "  \u001b[90m[38a345b3] \u001b[39m\u001b[92m+ Libuuid_jll v2.40.3+0\u001b[39m\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[d3a379c0] \u001b[39m\u001b[92m+ LittleCMS_jll v2.12.0+0\u001b[39m\n",
      "  \u001b[90m[856f044c] \u001b[39m\u001b[92m+ MKL_jll v2025.0.1+1\u001b[39m\n",
      "  \u001b[90m[e7412a2a] \u001b[39m\u001b[92m+ Ogg_jll v1.3.5+1\u001b[39m\n",
      "  \u001b[90m[18a262bb] \u001b[39m\u001b[92m+ OpenEXR_jll v3.2.4+0\u001b[39m\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[643b3616] \u001b[39m\u001b[92m+ OpenJpeg_jll v2.4.0+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[458c3c95] \u001b[39m\u001b[92m+ OpenSSL_jll v1.1.23+1\u001b[39m\n",
      "  \u001b[90m[91d4177d] \u001b[39m\u001b[92m+ Opus_jll v1.3.3+0\u001b[39m\n",
      "  \u001b[90m[36c8627f] \u001b[39m\u001b[92m+ Pango_jll v1.56.1+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[30392449] \u001b[39m\u001b[92m+ Pixman_jll v0.43.4+0\u001b[39m\n",
      "  \u001b[90m[ea2cea3b] \u001b[39m\u001b[92m+ Qt5Base_jll v5.15.3+2\u001b[39m\n",
      "  \u001b[90m[a2964d1f] \u001b[39m\u001b[92m+ Wayland_jll v1.21.0+2\u001b[39m\n",
      "  \u001b[90m[2381bf8a] \u001b[39m\u001b[92m+ Wayland_protocols_jll v1.36.0+0\u001b[39m\n",
      "  \u001b[90m[02c8fc9c] \u001b[39m\u001b[92m+ XML2_jll v2.13.6+1\u001b[39m\n",
      "  \u001b[90m[aed1982a] \u001b[39m\u001b[92m+ XSLT_jll v1.1.42+0\u001b[39m\n",
      "  \u001b[90m[4f6342f7] \u001b[39m\u001b[92m+ Xorg_libX11_jll v1.8.6+3\u001b[39m\n",
      "  \u001b[90m[0c0b7dd1] \u001b[39m\u001b[92m+ Xorg_libXau_jll v1.0.12+0\u001b[39m\n",
      "  \u001b[90m[935fb764] \u001b[39m\u001b[92m+ Xorg_libXcursor_jll v1.2.3+0\u001b[39m\n",
      "  \u001b[90m[a3789734] \u001b[39m\u001b[92m+ Xorg_libXdmcp_jll v1.1.5+0\u001b[39m\n",
      "  \u001b[90m[1082639a] \u001b[39m\u001b[92m+ Xorg_libXext_jll v1.3.6+3\u001b[39m\n",
      "  \u001b[90m[d091e8ba] \u001b[39m\u001b[92m+ Xorg_libXfixes_jll v6.0.0+0\u001b[39m\n",
      "  \u001b[90m[a51aa0fd] \u001b[39m\u001b[92m+ Xorg_libXi_jll v1.8.2+0\u001b[39m\n",
      "  \u001b[90m[d1454406] \u001b[39m\u001b[92m+ Xorg_libXinerama_jll v1.1.5+0\u001b[39m\n",
      "  \u001b[90m[ec84b674] \u001b[39m\u001b[92m+ Xorg_libXrandr_jll v1.5.4+0\u001b[39m\n",
      "  \u001b[90m[ea2f1a96] \u001b[39m\u001b[92m+ Xorg_libXrender_jll v0.9.11+1\u001b[39m\n",
      "  \u001b[90m[14d82f49] \u001b[39m\u001b[92m+ Xorg_libpthread_stubs_jll v0.1.2+0\u001b[39m\n",
      "  \u001b[90m[c7cfdc94] \u001b[39m\u001b[92m+ Xorg_libxcb_jll v1.17.0+3\u001b[39m\n",
      "  \u001b[90m[cc61e674] \u001b[39m\u001b[92m+ Xorg_libxkbfile_jll v1.1.2+1\u001b[39m\n",
      "  \u001b[90m[12413925] \u001b[39m\u001b[92m+ Xorg_xcb_util_image_jll v0.4.0+1\u001b[39m\n",
      "  \u001b[90m[2def613f] \u001b[39m\u001b[92m+ Xorg_xcb_util_jll v0.4.0+1\u001b[39m\n",
      "  \u001b[90m[975044d2] \u001b[39m\u001b[92m+ Xorg_xcb_util_keysyms_jll v0.4.0+1\u001b[39m\n",
      "  \u001b[90m[0d47668e] \u001b[39m\u001b[92m+ Xorg_xcb_util_renderutil_jll v0.3.9+1\u001b[39m\n",
      "  \u001b[90m[c22f9ab0] \u001b[39m\u001b[92m+ Xorg_xcb_util_wm_jll v0.4.1+1\u001b[39m\n",
      "  \u001b[90m[35661453] \u001b[39m\u001b[92m+ Xorg_xkbcomp_jll v1.4.6+1\u001b[39m\n",
      "  \u001b[90m[33bec58e] \u001b[39m\u001b[92m+ Xorg_xkeyboard_config_jll v2.39.0+0\u001b[39m\n",
      "  \u001b[90m[c5fb5394] \u001b[39m\u001b[92m+ Xorg_xtrans_jll v1.5.1+0\u001b[39m\n",
      "  \u001b[90m[3161d3a3] \u001b[39m\u001b[92m+ Zstd_jll v1.5.7+1\u001b[39m\n",
      "  \u001b[90m[214eeab7] \u001b[39m\u001b[92m+ fzf_jll v0.56.3+0\u001b[39m\n",
      "  \u001b[90m[a4ae2306] \u001b[39m\u001b[92m+ libaom_jll v3.11.0+0\u001b[39m\n",
      "  \u001b[90m[0ac62f75] \u001b[39m\u001b[92m+ libass_jll v0.15.2+0\u001b[39m\n",
      "  \u001b[90m[1183f4f0] \u001b[39m\u001b[92m+ libdecor_jll v0.2.2+0\u001b[39m\n",
      "  \u001b[90m[f638f0a6] \u001b[39m\u001b[92m+ libfdk_aac_jll v2.0.3+0\u001b[39m\n",
      "  \u001b[90m[b53b4c65] \u001b[39m\u001b[92m+ libpng_jll v1.6.47+0\u001b[39m\n",
      "  \u001b[90m[075b6546] \u001b[39m\u001b[92m+ libsixel_jll v1.10.5+0\u001b[39m\n",
      "  \u001b[90m[f27f6e37] \u001b[39m\u001b[92m+ libvorbis_jll v1.3.7+2\u001b[39m\n",
      "\u001b[32m⌃\u001b[39m \u001b[90m[c5f90fcd] \u001b[39m\u001b[92m+ libwebp_jll v1.4.0+0\u001b[39m\n",
      "  \u001b[90m[1317d2d5] \u001b[39m\u001b[92m+ oneTBB_jll v2022.0.0+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[1270edf5] \u001b[39m\u001b[92m+ x264_jll v2021.5.5+0\u001b[39m\n",
      "\u001b[33m⌅\u001b[39m \u001b[90m[dfaa095f] \u001b[39m\u001b[92m+ x265_jll v3.5.0+0\u001b[39m\n",
      "  \u001b[90m[d8fb68d0] \u001b[39m\u001b[92m+ xkbcommon_jll v1.4.1+2\u001b[39m\n",
      "  \u001b[90m[0dad84c5] \u001b[39m\u001b[92m+ ArgTools v1.1.2\u001b[39m\n",
      "  \u001b[90m[56f22d72] \u001b[39m\u001b[92m+ Artifacts v1.11.0\u001b[39m\n",
      "  \u001b[90m[2a0f44e3] \u001b[39m\u001b[92m+ Base64 v1.11.0\u001b[39m\n",
      "  \u001b[90m[ade2ca70] \u001b[39m\u001b[92m+ Dates v1.11.0\u001b[39m\n",
      "  \u001b[90m[8ba89e20] \u001b[39m\u001b[92m+ Distributed v1.11.0\u001b[39m\n",
      "  \u001b[90m[f43a241f] \u001b[39m\u001b[92m+ Downloads v1.6.0\u001b[39m\n",
      "  \u001b[90m[7b1f6079] \u001b[39m\u001b[92m+ FileWatching v1.11.0\u001b[39m\n",
      "  \u001b[90m[9fa8497b] \u001b[39m\u001b[92m+ Future v1.11.0\u001b[39m\n",
      "  \u001b[90m[b77e0a4c] \u001b[39m\u001b[92m+ InteractiveUtils v1.11.0\u001b[39m\n",
      "  \u001b[90m[4af54fe1] \u001b[39m\u001b[92m+ LazyArtifacts v1.11.0\u001b[39m\n",
      "  \u001b[90m[b27032c2] \u001b[39m\u001b[92m+ LibCURL v0.6.4\u001b[39m\n",
      "  \u001b[90m[76f85450] \u001b[39m\u001b[92m+ LibGit2 v1.11.0\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  \u001b[90m[8f399da3] \u001b[39m\u001b[92m+ Libdl v1.11.0\u001b[39m\n",
      "  \u001b[90m[37e2e46d] \u001b[39m\u001b[92m+ LinearAlgebra v1.11.0\u001b[39m\n",
      "  \u001b[90m[56ddb016] \u001b[39m\u001b[92m+ Logging v1.11.0\u001b[39m\n",
      "  \u001b[90m[d6f4376e] \u001b[39m\u001b[92m+ Markdown v1.11.0\u001b[39m\n",
      "  \u001b[90m[a63ad114] \u001b[39m\u001b[92m+ Mmap v1.11.0\u001b[39m\n",
      "  \u001b[90m[ca575930] \u001b[39m\u001b[92m+ NetworkOptions v1.2.0\u001b[39m\n",
      "  \u001b[90m[44cfe95a] \u001b[39m\u001b[92m+ Pkg v1.11.0\u001b[39m\n",
      "  \u001b[90m[de0858da] \u001b[39m\u001b[92m+ Printf v1.11.0\u001b[39m\n",
      "  \u001b[90m[3fa0cd96] \u001b[39m\u001b[92m+ REPL v1.11.0\u001b[39m\n",
      "  \u001b[90m[9a3f8284] \u001b[39m\u001b[92m+ Random v1.11.0\u001b[39m\n",
      "  \u001b[90m[ea8e919c] \u001b[39m\u001b[92m+ SHA v0.7.0\u001b[39m\n",
      "  \u001b[90m[9e88b42a] \u001b[39m\u001b[92m+ Serialization v1.11.0\u001b[39m\n",
      "  \u001b[90m[1a1011a3] \u001b[39m\u001b[92m+ SharedArrays v1.11.0\u001b[39m\n",
      "  \u001b[90m[6462fe0b] \u001b[39m\u001b[92m+ Sockets v1.11.0\u001b[39m\n",
      "  \u001b[90m[2f01184e] \u001b[39m\u001b[92m+ SparseArrays v1.11.0\u001b[39m\n",
      "  \u001b[90m[f489334b] \u001b[39m\u001b[92m+ StyledStrings v1.11.0\u001b[39m\n",
      "  \u001b[90m[fa267f1f] \u001b[39m\u001b[92m+ TOML v1.0.3\u001b[39m\n",
      "  \u001b[90m[a4e569a6] \u001b[39m\u001b[92m+ Tar v1.10.0\u001b[39m\n",
      "  \u001b[90m[8dfed614] \u001b[39m\u001b[92m+ Test v1.11.0\u001b[39m\n",
      "  \u001b[90m[cf7118a7] \u001b[39m\u001b[92m+ UUIDs v1.11.0\u001b[39m\n",
      "  \u001b[90m[4ec0a83e] \u001b[39m\u001b[92m+ Unicode v1.11.0\u001b[39m\n",
      "  \u001b[90m[e66e0078] \u001b[39m\u001b[92m+ CompilerSupportLibraries_jll v1.1.1+0\u001b[39m\n",
      "  \u001b[90m[deac9b47] \u001b[39m\u001b[92m+ LibCURL_jll v8.6.0+0\u001b[39m\n",
      "  \u001b[90m[e37daf67] \u001b[39m\u001b[92m+ LibGit2_jll v1.7.2+0\u001b[39m\n",
      "  \u001b[90m[29816b5a] \u001b[39m\u001b[92m+ LibSSH2_jll v1.11.0+1\u001b[39m\n",
      "  \u001b[90m[c8ffd9c3] \u001b[39m\u001b[92m+ MbedTLS_jll v2.28.6+0\u001b[39m\n",
      "  \u001b[90m[14a3606d] \u001b[39m\u001b[92m+ MozillaCACerts_jll v2023.12.12\u001b[39m\n",
      "  \u001b[90m[4536629a] \u001b[39m\u001b[92m+ OpenBLAS_jll v0.3.27+1\u001b[39m\n",
      "  \u001b[90m[05823500] \u001b[39m\u001b[92m+ OpenLibm_jll v0.8.1+2\u001b[39m\n",
      "  \u001b[90m[efcefdf7] \u001b[39m\u001b[92m+ PCRE2_jll v10.42.0+1\u001b[39m\n",
      "  \u001b[90m[bea87d4a] \u001b[39m\u001b[92m+ SuiteSparse_jll v7.7.0+0\u001b[39m\n",
      "  \u001b[90m[83775a58] \u001b[39m\u001b[92m+ Zlib_jll v1.2.13+1\u001b[39m\n",
      "  \u001b[90m[8e850b90] \u001b[39m\u001b[92m+ libblastrampoline_jll v5.11.0+0\u001b[39m\n",
      "  \u001b[90m[8e850ede] \u001b[39m\u001b[92m+ nghttp2_jll v1.59.0+0\u001b[39m\n",
      "  \u001b[90m[3f19e933] \u001b[39m\u001b[92m+ p7zip_jll v17.4.0+2\u001b[39m\n",
      "\u001b[36m\u001b[1m        Info\u001b[22m\u001b[39m Packages marked with \u001b[32m⌃\u001b[39m and \u001b[33m⌅\u001b[39m have new versions available. Those with \u001b[32m⌃\u001b[39m may be upgradable, but those with \u001b[33m⌅\u001b[39m are restricted by compatibility constraints from upgrading. To see why use `status --outdated -m`\n",
      "\u001b[92m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "  17272.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mUnsafeAtomics\u001b[39m\n",
      "  14045.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mlibsixel_jll\u001b[39m\n",
      "  11017.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mGPUArraysCore\u001b[39m\n",
      "  11003.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mSetfield\u001b[39m\n",
      "   1689.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLibtiff_jll\u001b[39m\n",
      "  19937.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStaticArrays\u001b[39m\n",
      "   4642.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mImageShow\u001b[39m\n",
      "   6877.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mPNGFiles\u001b[39m\n",
      "   3117.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mQOI\u001b[39m\n",
      "   7116.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mJpegTurbo\u001b[39m\n",
      "  12297.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mFFMPEG_jll\u001b[39m\n",
      "   2142.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mXTermColors\u001b[39m\n",
      "   4894.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mOpenEXR\u001b[39m\n",
      "   3447.2 ms\u001b[32m  ✓ \u001b[39mFileIO → HTTPExt\n",
      "   1805.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mQt5Base_jll\u001b[39m\n",
      "   1578.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStatic\u001b[39m\n",
      "   1473.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mAtomix\u001b[39m\n",
      "   4256.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mNetpbm\u001b[39m\n",
      "    847.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mArrayInterface → ArrayInterfaceGPUArraysCoreExt\u001b[39m\n",
      "   1618.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLittleCMS_jll\u001b[39m\n",
      "   1700.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mlibwebp_jll\u001b[39m\n",
      "   6177.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mSixel\u001b[39m\n",
      "   2311.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mArnoldiMethod\u001b[39m\n",
      "   1394.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStaticArrays → StaticArraysChainRulesCoreExt\u001b[39m\n",
      "   1284.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStaticArrays → StaticArraysStatisticsExt\u001b[39m\n",
      "   6842.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mCoordinateTransformations\u001b[39m\n",
      "   6555.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mRegionTrees\u001b[39m\n",
      "   1490.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mConstructionBase → ConstructionBaseStaticArraysExt\u001b[39m\n",
      "   1248.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mAdapt → AdaptStaticArraysExt\u001b[39m\n",
      "   2867.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mRotations\u001b[39m\n",
      "   3930.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mFFMPEG\u001b[39m\n",
      "    938.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mBitTwiddlingConvenienceFunctions\u001b[39m\n",
      "   2302.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStaticArrayInterface\u001b[39m\n",
      "   1874.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mCPUSummary\u001b[39m\n",
      "   7314.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mGR_jll\u001b[39m\n",
      "   1414.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mOpenJpeg_jll\u001b[39m\n",
      "   4918.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mWebP\u001b[39m\n",
      "   4127.7 ms\u001b[32m  ✓ \u001b[39mImageInTerminal\n",
      "   3014.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mNearestNeighbors\u001b[39m\n",
      "   5617.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mGraphs\u001b[39m\n",
      "   3470.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mInterpolations\u001b[39m\n",
      "   1597.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mRotations → RotationsRecipesBaseExt\u001b[39m\n",
      "   1300.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mHostCPUFeatures\u001b[39m\n",
      "   1586.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStaticArrayInterface → StaticArrayInterfaceStaticArraysExt\u001b[39m\n",
      "   5102.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mKernelAbstractions\u001b[39m\n",
      "    984.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStaticArrayInterface → StaticArrayInterfaceOffsetArraysExt\u001b[39m\n",
      "   1047.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mCloseOpenIntervals\u001b[39m\n",
      "   1214.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLayoutPointers\u001b[39m\n",
      "   2351.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mPolyesterWeave\u001b[39m\n",
      "   3140.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mImageMagick_jll\u001b[39m\n",
      "   7361.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mClustering\u001b[39m\n",
      "  16068.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mGR\u001b[39m\n",
      "   6559.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mSimpleWeightedGraphs\u001b[39m\n",
      "   5164.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mInterpolations → InterpolationsUnitfulExt\u001b[39m\n",
      "  64418.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mPolynomials\u001b[39m\n",
      "   4114.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mImageTransformations\u001b[39m\n",
      "   2610.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mKernelAbstractions → LinearAlgebraExt\u001b[39m\n",
      "   2657.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mKernelAbstractions → SparseArraysExt\u001b[39m\n",
      "   1714.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mTiledIteration\u001b[39m\n",
      "  89127.4 ms\u001b[32m  ✓ \u001b[39mJLD2\n",
      "   2582.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mPolynomials → PolynomialsChainRulesCoreExt\u001b[39m\n",
      "  11869.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mImageMagick\u001b[39m\n",
      "   3424.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mPolynomials → PolynomialsFFTWExt\u001b[39m\n",
      "  16460.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mVectorizationBase\u001b[39m\n",
      "   5152.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mImageBinarization\u001b[39m\n",
      "   6687.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mImageContrastAdjustment\u001b[39m\n",
      "   5350.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mMetaGraphs\u001b[39m\n",
      "   2335.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mSLEEFPirates\u001b[39m\n",
      "  12905.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mNNlib\u001b[39m\n",
      "   2030.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mNNlib → NNlibFFTWExt\u001b[39m\n",
      "   1895.3 ms\u001b[32m  ✓ \u001b[39mOneHotArrays\n",
      "  84357.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLoopVectorization\u001b[39m\n",
      "  32758.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mImageMorphology\u001b[39m\n",
      " 232154.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mTiffImages\u001b[39m\n",
      "   3602.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mImageDistances\u001b[39m\n",
      "   5133.0 ms\u001b[32m  ✓ \u001b[39mImageIO\n",
      " 166433.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mImageFiltering\u001b[39m\n",
      " 204698.4 ms\u001b[32m  ✓ \u001b[39mPlots\n",
      "  22385.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mImageSegmentation\u001b[39m\n",
      "  29427.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mImageCorners\u001b[39m\n",
      "  30571.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mImageQualityIndexes\u001b[39m\n",
      "  19587.6 ms\u001b[32m  ✓ \u001b[39mImages\n",
      "  35105.0 ms\u001b[32m  ✓ \u001b[39mPlots → FileIOExt\n",
      "  38256.7 ms\u001b[32m  ✓ \u001b[39mPlots → ImageInTerminalExt\n",
      "  39420.0 ms\u001b[32m  ✓ \u001b[39mPlots → UnitfulExt\n",
      "  85 dependencies successfully precompiled in 380 seconds. 247 already precompiled.\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `C:\\Users\\danie\\.julia\\registries\\General.toml`\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Cairo_jll ──────────── v1.18.4+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m SimpleWeightedGraphs ─ v1.5.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Pixman_jll ─────────── v0.44.2+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Adapt ──────────────── v4.3.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m DataStructures ─────── v0.18.22\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\danie\\CHEME5820\\CHEME-5820-Labs-Spring-2025\\labs\\week-9\\L9b\\Project.toml`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\danie\\CHEME5820\\CHEME-5820-Labs-Spring-2025\\labs\\week-9\\L9b\\Manifest.toml`\n",
      "  \u001b[90m[79e6a3ab] \u001b[39m\u001b[93m↑ Adapt v4.2.0 ⇒ v4.3.0\u001b[39m\n",
      "  \u001b[90m[864edb3b] \u001b[39m\u001b[93m↑ DataStructures v0.18.20 ⇒ v0.18.22\u001b[39m\n",
      "  \u001b[90m[47aef6b3] \u001b[39m\u001b[93m↑ SimpleWeightedGraphs v1.4.0 ⇒ v1.5.0\u001b[39m\n",
      "  \u001b[90m[83423d85] \u001b[39m\u001b[93m↑ Cairo_jll v1.18.2+1 ⇒ v1.18.4+0\u001b[39m\n",
      "  \u001b[90m[30392449] \u001b[39m\u001b[93m↑ Pixman_jll v0.43.4+0 ⇒ v0.44.2+0\u001b[39m\n",
      "\u001b[92m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "   3868.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mAdapt\u001b[39m\n",
      "   4024.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mDataStructures\u001b[39m\n",
      "   3553.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mPixman_jll\u001b[39m\n",
      "    772.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mOffsetArrays → OffsetArraysAdaptExt\u001b[39m\n",
      "   1022.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mGPUArraysCore\u001b[39m\n",
      "   1204.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mAdapt → AdaptSparseArraysExt\u001b[39m\n",
      "   1144.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mSortingAlgorithms\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   1406.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mAdapt → AdaptStaticArraysExt\u001b[39m\n",
      "   1823.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mCairo_jll\u001b[39m\n",
      "   2111.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mArrayInterface → ArrayInterfaceGPUArraysCoreExt\u001b[39m\n",
      "   5236.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStatsBase\u001b[39m\n",
      "    Interpolations\u001b[36m Being precompiled by another process (pid: 32220, pidfile: C:\\Users\\danie\\.julia\\compiled\\v1.11\\Interpolations\\VpKVx_UQMvD.ji.pidfile)\u001b[39m\n",
      "   7729.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mImageMorphology\u001b[39m\n",
      "   8779.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mGraphs\u001b[39m\n",
      "   7474.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mKernelAbstractions\u001b[39m\n",
      "   2372.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mHarfBuzz_jll\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "include(\"Include.jl\"); # load a bunch of libs, including the ones we need to work with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc8fb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_extension(file::String) = file[findlast(==('.'), file)+1:end]; # helper function to get the file extension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b64811",
   "metadata": {},
   "source": [
    "### Load the MINST digits data set\n",
    "In this example, we'll use a Hopfield network to learn a single image pattern from [the MINST handwritten digits dataset](https://en.wikipedia.org/wiki/MNIST_database). The goal is to train the network to recognize a digit, e.g., \"3\" or \"5\", etc, and then retrieve it from a noisy input.\n",
    "\n",
    "Load a training image dataset that we'll encode into the Hopfield network. We'll save training data in the `training_image_dataset` variable.\n",
    "* _What's in the training dataset_? The `training_image_dataset` will be of type `Vector{Tuple{Vector{Float32}, OneHotVector{UInt32}}}` where the first element is the input data `x.` The second element is the `label,` i.e., whether the image corresponds to `0,....,9`. However, the label is encoded as a `OneHotVector` (see below).\n",
    "* _Hmmm. That's strange_. The `Vector{Tuple{Vector{Float32}, OneHotVector{UInt32}}}` type has a couple of _weird features_. First, notice that the floating point is `Float32`, not the default `Float64`. Next, the labels are [One Hot ecoded](https://en.wikipedia.org/wiki/One-hot). Finally, the input data `x` is a Vector, not a Matrix (even though the original image is a matrix of `Gray` values).\n",
    "\n",
    "However, before we load the training data, let's set some constants, which we use below. The comment next to each constant describes it, its permissible values, units, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09a8e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_training_examples = 30; # how many training examples of *each* number to include from the library\n",
    "number_digit_array = range(0,length=10,step=1) |> collect; # numbers 0 ... 9\n",
    "number_of_rows = 28; # number of rows in the image\n",
    "number_of_cols = 28; # number of cols in the image\n",
    "number_of_pixels = number_of_rows*number_of_cols; # how many pixels do we have in the image?\n",
    "number_of_images_to_memorize = 2; # number of images that we want to encode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acadc29",
   "metadata": {},
   "source": [
    "`Unhide` the code blocks below to see how we construct and populate the `training_image_dataset` variable. First, we load all the images into the `training_image_dictionary::Dict{Int64, Array{Gray{N0f8},3}}`, and then we'll convert these to a vector format below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817ba7cd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "training_image_dictionary = let\n",
    "    training_image_dictionary = Dict{Int64, Array{Gray{N0f8},3}}();\n",
    "    for i ∈ number_digit_array\n",
    "        \n",
    "        # create a set for this digit -\n",
    "        image_digit_array = Array{Gray{N0f8},3}(undef, number_of_rows, number_of_cols, number_of_training_examples);\n",
    "        files = readdir(joinpath(_PATH_TO_IMAGES,\"$(i)\")); \n",
    "        imagecount = 1;\n",
    "        for fileindex ∈ 1:number_of_training_examples\n",
    "            filename = files[fileindex];\n",
    "            ext = file_extension(filename)\n",
    "            if (ext == \"jpg\")\n",
    "                image_digit_array[:,:,fileindex] = joinpath(_PATH_TO_IMAGES, \"$(i)\", filename) |> x-> FileIO.load(x);\n",
    "                imagecount += 1\n",
    "            end\n",
    "        end\n",
    "    \n",
    "        # capture -\n",
    "        training_image_dictionary[i] = image_digit_array\n",
    "    end\n",
    "    training_image_dictionary\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e30164",
   "metadata": {},
   "source": [
    "Next, we take the images in array format and vectorize them. \n",
    "* _What do we mean by vectorize_? Each $N\\times{N}$ image array containing the grayscale values at each pixel is converted to an $N^{2}$ vector of values. What image class, i.e., what number it represents, is then converted to [one-hot format](https://en.wikipedia.org/wiki/One-hot). The converted data is stored in the `training_image_dataset::Vector{Tuple{Vector{Float32}, OneHotVector{UInt32}}}` variable.\n",
    "* _What's the deal with Float32_? Most neural network libraries (or other machine learning calculations) use `Float32` (or lower) to save memory because of the large number of parameters associated with the network. Additionally, model training is often carried out using specialized hardware [such as Graphical Processing Units (GPUs)](https://www.nvidia.com/en-us/data-center/h100/), which has different memory constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69261c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_dataset = let\n",
    "    training_image_dataset = Vector{Tuple{Vector{Float32}, OneHotVector{UInt32}}}()\n",
    "    for i ∈ number_digit_array\n",
    "        Y = onehot(i, number_digit_array);\n",
    "        X = training_image_dictionary[i];\n",
    "        \n",
    "        for t ∈ 1:number_of_training_examples\n",
    "            D = Array{Float32,1}(undef, number_of_pixels);\n",
    "            linearindex = 1;\n",
    "            for row ∈ 1:number_of_rows\n",
    "                for col ∈ 1:number_of_cols\n",
    "                    D[linearindex] = X[row,col,t] |> x-> convert(Float32,x);\n",
    "                    linearindex+=1;\n",
    "                end\n",
    "            end\n",
    "    \n",
    "            training_tuple = (D,Y);\n",
    "            push!(training_image_dataset,training_tuple);\n",
    "        end\n",
    "    end\n",
    "    training_image_dataset\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf0826a",
   "metadata": {},
   "source": [
    "## Task 2: Learn the Weights of the Network\n",
    "In this task, we'll learn the weights of the Hopfield network using the training data. A [Hopfield network](https://en.wikipedia.org/wiki/Hopfield_network) uses a special [Hebbian learning rule](chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://arxiv.org/pdf/2010.01472), where the weights $w_{ij}\\in\\mathbf{W}$ are _encoded_ by the image (or memory) the network is trying to learn. \n",
    "\n",
    "Suppose we wish our network to memorize $m$-images, where each image is an $n\\times{n}$ collection of black and white pixels represented as a vector $\\mathbf{s}_{i}\\in\\left\\{-1,1\\right\\}\\in{R}^{n^2}$. We encode the image using the following rule: if the pixel is white, we set the value to $1$, and if the pixel is black, we set the value to $-1$. Then, the weights that encode these $m$-images are given by:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\mathbf{W} = \\frac{1}{m}\\cdot\\sum_{i=1}^{m}\\mathbf{s}_{i}\\otimes\\mathbf{s}_{i}^{\\top}\n",
    "\\end{equation*}\n",
    "$$\n",
    "where $\\mathbf{s}_{i}$ denotes the state (pixels) of the image we want to memorize, and [$\\otimes$ denotes the outer product](https://en.wikipedia.org/wiki/Outer_product). Thus, the weights are the average of all of our memories!\n",
    "\n",
    "* __How big is $m$?__: The maximum theoretical storage limit $K_{\\text{max}}$ (the maximum number of possible images that can be stored) of a Hopfield network, using the standard Hebbian learning rule, is approximately $K_{max}\\sim{0.138}{N}$, where $N$ is the number of neurons (nodes) in the network. Thus, the network can reliably store about 14% of its size in patterns before retrieval errors become significant due to interference between stored patterns.\n",
    "* Paper exploring this theoretical limit: [Folli V, Leonetti M, Ruocco G. On the Maximum Storage Capacity of the Hopfield Model. Front Comput Neurosci. 2017 Jan 10;10:144. doi: 10.3389/fncom.2016.00144. PMID: 28119595; PMCID: PMC5222833.](https://pubmed.ncbi.nlm.nih.gov/28119595/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ae15b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kmax = 0.138*number_of_pixels |> x-> round(x, RoundDown) # max number of images the network can memorize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dc98c8",
   "metadata": {},
   "source": [
    "Next, let's generate a random set of image indexes that we encode into the model. We'll store this collection in the `image_index_set_to_encode::Set{Int64}` variable.\n",
    "* _How do we build this set_? We specify the number of images that we want in the `number_of_images_to_memorize::Int` variable; then we iterate using [a `while-loop`](https://docs.julialang.org/en/v1/base/base/#while) until we generate the required number of indexes _randomly_. We stop the loop once we hit our target number. Fun data structure question: why do we use [a Julia `Set`](https://docs.julialang.org/en/v1/base/collections/#Base.Set) instead of an array?\n",
    "\n",
    "`Unhide` the code block below to see how we generated the `image_index_set_to_encode::Set{Int}` index set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7473649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index_set_to_encode = let\n",
    "\n",
    "    # how many images do we want to encode?\n",
    "    number_of_possible_images = length(training_image_dataset);\n",
    "    image_index_set_to_encode = Set{Int64}();\n",
    "\n",
    "    is_ok_to_stop = false; # iteration flag\n",
    "    while (is_ok_to_stop == false)\n",
    "        \n",
    "        # generate a random index -\n",
    "        j = rand(1:number_of_possible_images);\n",
    "        push!(image_index_set_to_encode, j); # add to the image set -\n",
    "\n",
    "        # check: have we hit the number that we want?\n",
    "        if (length(image_index_set_to_encode) ≥ number_of_images_to_memorize)\n",
    "            is_ok_to_stop = true;\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # return \n",
    "    image_index_set_to_encode;\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faf9caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index_set_to_encode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df0ae0e-3cbe-4664-a5af-421ca8496c8b",
   "metadata": {},
   "source": [
    "Let's see what images we selected at random. Thus, these will be the `true` images. In a perfect world, our network will be able to retrieve each of these images, given the appropriate input vector $\\mathbf{s}_{\\circ}$. `Unhide` the code block below to see how we decoded and displayed these images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab441280-7d8d-4e4e-b0d3-45163fbb3d12",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "let\n",
    "\n",
    "    index_vector = image_index_set_to_encode |> collect |> sort; # we'll process this in this order \n",
    "    for example_image_index ∈ index_vector\n",
    "    \n",
    "        ŝₖ = training_image_dataset[example_image_index][1]; # raw state *not* scaled to -1,1\n",
    "        s = Array{Int32,1}(undef, number_of_pixels); # initialize some space\n",
    "        for i ∈ 1:number_of_pixels\n",
    "            pixel =  ŝₖ[i] |> x-> round(Int,x);\n",
    "            if pixel == 0.0\n",
    "                s[i] = -1\n",
    "            else\n",
    "                s[i] = 1;\n",
    "            end\n",
    "        end\n",
    "        display(decode(s) |> img -> Gray.(img))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f502a66",
   "metadata": {},
   "source": [
    "### Encode a Hopfield model\n",
    "Now that we have the training images let's encode the model. We'll compute the weights and the bias term and store them [in an instance of the `MyClassicalHopfieldNetworkModel` type](src/Types.jl). The weights are stored in the `W` field, and the bias term is stored in the `b` field. \n",
    "* _How do we build this model_? We build the model (and estimate the weight matrix and bias vector) using [the `build(...)` method](src/Factory.jl). This method takes the type of thing we want to construct, namely [a `MyClassicalHopfieldNetworkModel` instance](src/Types.jl), and the memories we want to encode. The (vectorized) memories are stored in the columns of an array. The [`build(...)` method](src/Compute.jl) returns a model instance with the `W` and `b` fields populated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e882f3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model = let\n",
    "\n",
    "    # initialize -\n",
    "    number_of_images_to_learn = length(image_index_set_to_encode);\n",
    "    linearimagecollection = Array{Int32,2}(undef, number_of_pixels, number_of_images_to_learn); # images on columns\n",
    "    \n",
    "    # turn our set into a sorted vector -\n",
    "    index_vector = image_index_set_to_encode |> collect |> sort; # we'll process this in this order \n",
    "    for k ∈ eachindex(index_vector)\n",
    "        \n",
    "        j = index_vector[k];\n",
    "        ŝₖ = training_image_dataset[j][1]; # raw state *not* scaled to -1,1\n",
    "\n",
    "        # fill the columns of the array -\n",
    "        for i ∈ 1:number_of_pixels\n",
    "            pixel =  ŝₖ[i] |> x-> round(Int,x);\n",
    "            if pixel == 0.0 # hmmm\n",
    "                linearimagecollection[i,k] = -1;\n",
    "            else\n",
    "                linearimagecollection[i,k] = 1;\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # build the model using the encode function -\n",
    "    model = build(MyClassicalHopfieldNetworkModel, (\n",
    "        memories = linearimagecollection,\n",
    "    ));\n",
    "\n",
    "    # return -\n",
    "    model\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b58401",
   "metadata": {},
   "source": [
    "## Task 3: Retrieve a memory from the network\n",
    "In this task, we will retrieve a memory from the Hopfield network starting from a random state vector $\\mathbf{s}_{\\circ}$. Let's start by specifying which of the images we expect to recover in the `imageindextorecover::Int` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec6f08a-f892-48ad-bf49-3ba7d0f35dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageindextorecover = 2; # which element of the index vector will we choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c703bda-8ad5-4b7b-8340-f7146318f74e",
   "metadata": {},
   "source": [
    "Then, we'll build a corrupted initial condition vector based on this image, which we'll store in the `sₒ::Array{Int32,1}` variable. We'll iterate through each pixel from the original image and convert it to a `[-1,1]` scale. However, sometimes we'll make a mistake. \n",
    "* _What is the $\\theta$ parameter_? The $\\theta$ hyperparameter controls how often we make mistakes. In particular, we roll a random number $p$. If $p\\leq\\theta$, we scale the original pixel value _correctly_. However, if $p<\\theta$, we put the incorrect pixel value in this location in the state vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a993ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "sₒ = let\n",
    "\n",
    "    index_vector = image_index_set_to_encode |> collect |> sort; # we'll process this in this order\n",
    "    index_of_image_to_encode = index_vector[imageindextorecover]; # -or- choose random\n",
    "    \n",
    "    # initialize -\n",
    "    ŝₖ = training_image_dataset[index_of_image_to_encode][1]; # raw state *not* scaled to -1,1\n",
    "    sₒ = Array{Int32,1}(undef, number_of_pixels); # initialize some space\n",
    "    θ = 0.60; # threshold correct\n",
    "\n",
    "    for i ∈ 1:number_of_pixels\n",
    "        pixel =  ŝₖ[i] |> x-> round(Int,x); # We have some gray-scale values in the original vector, need to round\n",
    "        if pixel == 0.0\n",
    "            sₒ[i] = (rand() ≤ θ) ? -1 : 1\n",
    "        else\n",
    "            sₒ[i] = 1;\n",
    "        end\n",
    "    end\n",
    "    sₒ\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec3b03f",
   "metadata": {},
   "source": [
    "What does the initial state vector $\\mathbf{s}_{\\circ}$ look like (this should be a corrupted version of the `imageindextorecover` image):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa316aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode(sₒ) |> img -> Gray.(img) # corrupted true image. This is what we give the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314bacb1",
   "metadata": {},
   "source": [
    "Now that we have a starting memory encoded in the state vector $\\mathbf{s}_{\\circ}$, can we recover the original image?\n",
    "* _What do we expect to happen?_ Starting from the initial random configuration, we'll randomly select pixels and flip them (or at least evaluate the activation function). We'll store a copy of the (potentially) flipped state and compute the energy for the (potentially) flipped state. We expect the energy to decrease as we converge toward the correct image.\n",
    "* _Implementation_: We implemented the recovery alogorithm above in [the `recover(...)` method](src/Compute.jl). This method takes our `model::MyClassicalHopfieldNetworkModel` instance, the initial configuration vector `sₒ::Array{Int32,1}`, the number `maxiterations::Int64` and the index of the true image that we are trying to recover, i.e., the `imageindextorecover::Int` variable. It returns the `frames` and `energydictionary` variables which hold information about each iteration of the recovery algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f036d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, energydictionary = recover(model, sₒ, maxiterations=25*number_of_pixels, trueindex = imageindextorecover);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999dcdc7-f87c-4201-b82c-6212d4b07ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351c54da-c421-4608-9ea1-31cab6af1ec2",
   "metadata": {},
   "source": [
    "Which image does the model recover?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8fc240",
   "metadata": {},
   "outputs": [],
   "source": [
    "let\n",
    "    lastindex = keys(energydictionary) |> collect |> sort |> last\n",
    "    energydictionary[lastindex]\n",
    "    frames[lastindex] |> s-> decode(s) |> img -> Gray.(img)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede849db-6013-4637-935c-efb6450427ac",
   "metadata": {},
   "source": [
    "What is the energy that we recover?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c6d22d-c289-48e3-bfa1-6bcdd28c7166",
   "metadata": {},
   "outputs": [],
   "source": [
    "let\n",
    "    lastindex = keys(energydictionary) |> collect |> sort |> last\n",
    "    energydictionary[lastindex]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e88163c-4da5-43d9-a6b0-503e99a857bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a28d3b",
   "metadata": {},
   "source": [
    "Does the energy decrease as we flip the states in the network? Let's plot the values in the `energydictionary::Dict{Int64, Float32}` and see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22d8d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "let\n",
    "    p = plot(bg=\"gray95\", background_color_outside=\"white\", framestyle = :box, fg_legend = :transparent); \n",
    "    plot!(energydictionary, lw=3,c=:navy, label=\"\");\n",
    "    xlabel!(\"Step index (AU)\", fontsize=18)\n",
    "    ylabel!(\"Network configuration energy (AU)\", fontsize=18)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad0b138-fa14-44ba-9bbd-e6ce8bf97645",
   "metadata": {},
   "source": [
    "# Next time\n",
    "The classical version of the Hopfield network encodes only binary (or bipolar) memories. It would be much better if we could encode continuous memories. Toward this challenge, we look at [Modern Hopfield networks](https://arxiv.org/abs/2008.02217) in lecture `L9c`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be00346c",
   "metadata": {},
   "source": [
    "# Extra\n",
    "Let's look at a movie showing how the model changes each iteration. Set the `do_I_want_to_see_a_movie = true` to see a frame-by-frame update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6c0e01-e9f1-4e39-be98-7be9b3054452",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_I_want_to_see_a_movie = false; # Flag that controls movie play {true | false}. Movie is *slow*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3311db",
   "metadata": {},
   "outputs": [],
   "source": [
    "let\n",
    "    \n",
    "    if (do_I_want_to_see_a_movie == true)\n",
    "        number_of_frames_to_view = length(frames);\n",
    "        for i ∈ 0:(number_of_frames_to_view-1)\n",
    "            image_index_to_view = i;\n",
    "            s = frames[image_index_to_view];\n",
    "            image = decode(s);\n",
    "            display(Gray.(image))\n",
    "            println(\"Turn index = $(i)\")\n",
    "            IJulia.clear_output(true) # may not work in VSCode?\n",
    "            sleep(0.01) # add some delay\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
