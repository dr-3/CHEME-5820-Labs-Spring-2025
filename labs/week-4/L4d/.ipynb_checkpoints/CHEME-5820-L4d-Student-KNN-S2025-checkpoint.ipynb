{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a09c9ee1-3ba4-43bf-8678-65d5f7ac2481",
   "metadata": {},
   "source": [
    "# L4d: K-Nearest Neighbor (KNN) Classification\n",
    "In this lab, we'll use the kernelized variant of [K-nearest neighbor classification](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) to classify randomly overlayed datasets. In particular, we'll take advantage of the kernel trick to map our two-dimensional dataset and into a higher dimensional space where it _may_ be linearly separable.\n",
    "\n",
    "### Backstory: The Kernel Trick\n",
    "The kernel trick is a clever technique in machine learning that allows algorithms to operate in high-dimensional feature spaces without explicitly computing the coordinates in that space. It enables linear classifiers to solve nonlinear problems by implicitly mapping data into a higher-dimensional space, making complex pattern analysis more computationally efficient.\n",
    "\n",
    "* __Mapping to higher dimensions__? We can take a feature vector $\\mathbf{x}\\in\\mathbb{R}^{n}$ and combine its elements to make a higher dimensional object with $m$ components ($m>n$) using a feature map. For example, suppose we wanted to go from a scalar to a four-dimensional object. In this case, we could propose a feature map $\\phi:\\mathbb{R}\\to\\mathbb{R}^{4}$, such that $\\phi(x) = \\left(1,x,x^{2}, x^{3}\\right)^{\\top}$. In the language of models, this is still a linear model because we can write something like: $y = \\phi\\left(x\\right)^{\\top}\\theta$, where $\\theta\\in\\mathbb{R}^{4}$ is an (unknown) parameter vector.\n",
    "* __Another meaning of kernel functions__: We know that the inner product $k(\\mathbf{x},\\mathbf{z}) = \\left<\\mathbf{x},\\mathbf{z}\\right>$ is a valid kernel function. However, the function $k(\\mathbf{x},\\mathbf{z}) = \\left<\\phi(\\mathbf{x}),\\phi(\\mathbf{z})\\right>$ is also a kernel function, i.e., we have applied some feature map $\\phi: \\mathbb{R}^{\\star}\\to\\mathbb{R}^{\\dagger}$ where $\\dagger>\\star$ to our input feature vectors and taken the inner product of the $\\dagger$-dimensional objects. Ok, but what is the feature map $\\phi$? How do I choose this? Perhaps if you have some insight, you could choose $\\phi$. \n",
    "* __TLDR: You don't choose a feature mapping $\\phi$__! By choosing a (valid) functional form for the kernel $k$, you are indirectly (implicitly) assuming a feature map $\\phi$. Thus, in a problem, when you iterate over functional forms for the $k$ function, each function gives a new _implicit_ feature mapping. Everything else stays the same.\n",
    "\n",
    "### Tasks\n",
    "Before we start, divide into teams and familiarize yourself with the lab. Then, execute the `Run All Cells` command to check if you (or your neighbor) have any code or setup issues. Code issues, then raise your hands - and let's get those fixed!\n",
    "\n",
    "* __Task 1: Setup, Data, Constants (10 min)__: Let's take 10 minutes to explore how we will generate the datasets we'll explore today. We'll work through how to generate linearly separable and non-linearly separable datasets.\n",
    "* __Task 2: K-Nearest Neighbor Classification (30 min)__: In this task, we'll build and train a Perceptron classification model, use the trained model to estimate the labels on unseen test data, and then compute the confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50249223-7ceb-4fab-bfd4-8e8c988a28ad",
   "metadata": {},
   "source": [
    "## Task 1: Setup, Data, and Prerequisites\n",
    "We set up the computational environment by including the `Include.jl` file, loading any needed resources, such as sample datasets, and setting up any required constants. The `Include.jl` file loads external packages, various functions that we will use in the exercise, and custom types to model the components of our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1b1f297-e5a0-4bf4-8110-b815ebd91115",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5469f9db-d799-4166-bf3b-940b230f5085",
   "metadata": {},
   "source": [
    "Next, let's set some constants we'll need for the data generation logic below. Please look at the comment next to the constant for a description of what it is, permissible values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db31f098-ca7e-4008-860d-9bd17dfdd630",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_label_one = 1000; # number of points in cloud 1 (must be ≥ 2)\n",
    "number_label_two = 1000; # number of points in cloud 2 (must be ≥ 2)\n",
    "total_number_of_points = (number_label_one + number_label_two);\n",
    "number_of_features = 3; # features: (x,y,l), where l is a generated label; see below.\n",
    "c̄₁ = (0.0, 0.0); # center for the cloud: fixed\n",
    "θ = 60*(π/180); # rotation angle (radians)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3c8b0d-dd15-4c9b-9ef3-cf52c215927a",
   "metadata": {},
   "source": [
    "Finally, let's set up the color dictionary to visualize the classification datasets. The keys of the `my_color_dictionary::Dict Int64, RGB` dictionary class labels, i.e., $ y\\in\\{1,-1\\}$ while the values are the colors mapped to that label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8357483f-0d46-43b8-936f-7e41d3500614",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_color_dictionary = Dict{Int64,RGB}();\n",
    "my_color_dictionary[1] = colorant\"#03045e\"; # color for Label = 1\n",
    "my_color_dictionary[-1] = colorant\"#e36414\"; # color for Label = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60405634-a57c-4d07-91d9-7d884a31f1ef",
   "metadata": {},
   "source": [
    "### Data\n",
    "We'll use [K-nearest neighbor classification](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) to classify datasets, including [the XOR dataset](https://en.wikipedia.org/wiki/Exclusive_or) that we construct. First, we'll generate a master dataset (which may or may not be linearly separable), then split it into (random) `training` and `test` subsets.\n",
    "* __Training data__: Training datasets are collections of labeled data used to teach machine learning models, allowing these tools to learn patterns and relationships within the data. In our case, we'll use the training data to estimate the classifier parameters $\\beta$.\n",
    "* __Test data__: Test datasets, on the other hand, are separate sets of labeled data used to evaluate the performance of trained models on unseen examples, providing an unbiased assessment of the _model's generalization capabilities_.\n",
    "\n",
    "Let's start by generating the master dataset `D::Array{Float64,2}`. This dataset will have two continuous features $\\mathbf{x}\\in\\mathbb{R}^{2}$ and a categorical label $y\\in\\{-1,1\\}$ and will be stored in the `D::Array{Float64,2}` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "008479d7-f335-4bf4-af6e-79c9b96e1a99",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `s₁` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `s₁` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[9]:11"
     ]
    }
   ],
   "source": [
    "D = let\n",
    "    \n",
    "    # initialize -\n",
    "    D = Array{Float64,2}(undef, total_number_of_points, number_of_features);\n",
    "\n",
    "    # uncomment me to generate data\n",
    "    # s₁ = generatedatacloud(c̄₁, number_of_points = number_label_one, label=1, r₁ = 0.0, r₂ = 1.0); # generate label 1 data\n",
    "    # s₂ = generatedatacloud(c̄₁, number_of_points = number_label_two, label=-1, r₁ = 2.0, r₂ = 3.0); # generate label 2 data\n",
    "\n",
    "    # mix s₁, s₂ together (randomly)\n",
    "    tmp = vcat(s₁,s₂)\n",
    "    random_perm_index_vector = randperm(total_number_of_points);\n",
    "    for i ∈ eachindex(random_perm_index_vector)\n",
    "        k = random_perm_index_vector[i]; # get the from col -\n",
    "        for j ∈ 1:number_of_features\n",
    "            D[i,j] = tmp[k,j];\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Finally, let's rotate the data a bit (counter-clockwise)\n",
    "    R = [\n",
    "        cos(θ) -sin(θ) ;\n",
    "        sin(θ) cos(θ) ;\n",
    "    ];\n",
    "\n",
    "    # keep the label, but apply the rotation the (x,y) data\n",
    "    D̂ = copy(D);\n",
    "    for i ∈ 1:total_number_of_points\n",
    "        x̂ = R*D[i,1:2];\n",
    "        D̂[i,1] = x̂[1];\n",
    "        D̂[i,2] = x̂[2];\n",
    "    end\n",
    "    \n",
    "    D̂ # return the data\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096702d7-6689-401b-84cd-6b6fcda6118e",
   "metadata": {},
   "source": [
    "#### Visualize dataset `D`\n",
    "`Unhide` the code block below to see how we plotted the dataset `D`, which contains two continuous features and a label. The color indicates the label.\n",
    "* __Summary__: We will get a different pattern of $\\pm{1}$ labels depending on radius $r_{1}$ and $r_{2}$ values, and any additional labeling logic $L(x,y)$ we used. The dark blue dots represent label `1`, while the orange data represents label `1`. Our classifier should be able to learn the mapping between the features and the labels for linearly separable datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3bd3870-a29f-430f-9e44-f30139d1fb5d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `D` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `D` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[11]:3"
     ]
    }
   ],
   "source": [
    "let\n",
    "\n",
    "    dataset = D; # what dataset am I looking at?\n",
    "    number_of_points_to_plot = size(dataset,1);\n",
    "    p = plot(bg=\"gray95\", background_color_outside=\"white\", framestyle = :box, fg_legend = :transparent); # make an empty plot\n",
    "\n",
    "    # plot label = 1\n",
    "    testlabel = 1;\n",
    "    i = findfirst(label -> label == testlabel,  dataset[:,3])\n",
    "    c = my_color_dictionary[testlabel]\n",
    "    scatter!([dataset[i,1]], [dataset[i,2]], label=\"Label: $(testlabel)\", c=c)\n",
    "\n",
    "    # plot label = -1\n",
    "    testlabel = -1;\n",
    "    i = findfirst(label -> label == testlabel,  dataset[:,3])\n",
    "    c = my_color_dictionary[testlabel]\n",
    "    scatter!([dataset[i,1]], [dataset[i,2]], label=\"Label: $(testlabel)\", c=c)\n",
    "\n",
    "    # plot all points\n",
    "    for i ∈ 1:number_of_points_to_plot\n",
    "        label = dataset[i,3]; # label\n",
    "        c = my_color_dictionary[label]\n",
    "        scatter!([dataset[i, 1]], [dataset[i, 2]], label=\"\", mec=:navy, c=c)\n",
    "    end\n",
    "    \n",
    "    xlabel!(\"Feature 1 (AU)\", fontsize=18);\n",
    "    ylabel!(\"Feature 2 (AU)\", fontsize=18);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3225885c-8a20-4909-8eb2-cbce1a49b34b",
   "metadata": {},
   "source": [
    "Next, let's split that dataset `D` into `training` and `test` subsets. We do this randomly, where the `number_of_training_examples::Int64` variable specifies the number of training points. The `training::Array{Float64,2}` data will be used to estimate the model parameters, and `test::Array{Float64,2}` will be used for model testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42bcb679-e0e5-4f9d-ad99-2078db199b2b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `D` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `D` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[13]:21"
     ]
    }
   ],
   "source": [
    "training, test = let\n",
    "\n",
    "    number_of_training_examples = 1200; # we make this number of\n",
    "    number_of_examples = total_number_of_points;\n",
    "    full_index_set = range(1,stop=number_of_examples,step=1) |> collect |> Set;\n",
    "    \n",
    "    # build index sets for training and testing\n",
    "    training_index_set = Set{Int64}();\n",
    "    should_stop_loop = false;\n",
    "    while (should_stop_loop == false)\n",
    "        i = rand(1:number_of_examples);\n",
    "        push!(training_index_set,i);\n",
    "\n",
    "        if (length(training_index_set) == number_of_training_examples)\n",
    "            should_stop_loop = true;\n",
    "        end\n",
    "    end\n",
    "    test_index_set = setdiff(full_index_set,training_index_set);\n",
    "\n",
    "    # build the test and train datasets -\n",
    "    training = D[training_index_set |> collect,:];\n",
    "    test = D[test_index_set |> collect,:];\n",
    "\n",
    "    # return\n",
    "    training, test\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875abf0f-ab0d-488d-89c1-da0854ab9718",
   "metadata": {},
   "source": [
    "## Task 2: K-Nearest Neighbor Classification\n",
    "In this task, we'll set up a K-nearest neighbor (KNN) classification for different datasets generated in _task 1_. As part of this, we will look at different kernel functions (or different distance metrics) and see how they perform.\n",
    "\n",
    "K-nearest neighbor (KNN) classification is a simple yet powerful machine learning algorithm for classification and regression tasks. The algorithm finds the $K$ closest data points to a new instance in the feature space and then classifies the new instance based on the majority class among these neighbors.\n",
    "\n",
    "* __Key assumption__: The key assumption of a [K-nearest neighbor classifier](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) is that _similar_ inputs have _similar_ labels (in classification tasks) or _similar_ outputs for K-nearest neighbor regression tasks. However, the wiggly aspect of this assumption is what we mean by _similar_.\n",
    "\n",
    "__Algorithm__\n",
    "* __Initialization__. You provide some _reference_ dataset $\\mathcal{D} = \\{(\\mathbf{x}_{i},y_{i}) \\mid i = 1,2,\\dots,n\\}$, where the vectors $\\mathbf{x}_i \\in \\mathbb{R}^{m}$ are $m$-dimensional feature vectors ($m\\ll{n}$) and the target variables are discrete labels $y_i \\in \\left\\{-1,1\\right\\}$. We'll use the reference dataset $\\mathcal{D}$ to compare our unknown points.\n",
    "* __Inference__: The distance (similarity) between a test feature vector $\\mathbf{z}$ and _all reference instances_ is computed; call this set $\\mathcal{S}$. Set $\\mathcal{S}$ is sorted from highest to lowest similarity. Then, a particular label is estimated from the labels of the top-K elements of the sorted neighbor set —- _decision rule_: Majority wins (but we could imagine other scenarios).\n",
    "\n",
    "We will try various kernel (distance) functions to see if the implicit transformation they encode will allow the pulling apart of the overlapping dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba66a231-5cdb-4d67-ad41-d673311e65ca",
   "metadata": {},
   "source": [
    "### Similarity: Build a Kernel Function\n",
    "In the code cell below, build a kernel function $k:\\mathbb{R}^{2}\\times\\mathbb{R}^{2}\\to\\mathbb{R}$. You can use a [kernel exported by the `KernelFunctions.jl` package](https://juliagaussianprocesses.github.io/KernelFunctions.jl/stable/), or make one up on your own. Save this function in the `k(x,y)::Function` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9d216c3-31a8-41b3-a985-b55c72051ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "k(x,y) = nothing; # TODO: update this with some distance or kernel "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2725a1-44b7-4667-9e2a-48aa1d4165da",
   "metadata": {},
   "source": [
    "#### Check: Is $k$ a valid Kernel function?\n",
    "A function $k:\\mathbb{R}^{m}\\times\\mathbb{R}^{m}\\to\\mathbb{R}$ is a _valid kernel function_ if and only if the kernel matrix $\\mathbf{K}\\in\\mathbb{R}^{n\\times{n}}$ is positive (semi)definite for all possible choices of the data vectors $\\mathbf{v}_i$, where $K_{ij} = k(\\mathbf{v}_i, \\mathbf{v}_j)$. If $\\mathbf{K}$ is positive (semi)definite, for any real-valued vector $\\mathbf{x}$, the Kernel matrix $\\mathbf{K}$ must satisfy $\\mathbf{x}^{\\top}\\mathbf{K}\\mathbf{x} \\geq 0$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19384b8c-215a-4524-a31e-9e80bb4158bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `test` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nHint: a global variable of this name also exists in Pkg.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `test` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nHint: a global variable of this name also exists in Pkg.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[18]:3"
     ]
    }
   ],
   "source": [
    "K = let\n",
    "\n",
    "    D₂ = test;\n",
    "    number_of_test_examples = size(D₂,1);\n",
    "    X₂ = D₂[:,1:end-1]; # data for test (notice no extra 1)\n",
    "    K = zeros(number_of_test_examples,number_of_test_examples);\n",
    "\n",
    "    for i ∈ 1:number_of_test_examples\n",
    "        vᵢ = X₂[i,:];\n",
    "        for j ∈ 1:number_of_test_examples\n",
    "            vⱼ = X₂[j,:];\n",
    "            # K[i,j] = k(vᵢ,vⱼ) # TODO: call your kernel (or distance function)\n",
    "        end\n",
    "    end\n",
    "    K\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aac8da-5449-4bdc-9611-7b54e679a59d",
   "metadata": {},
   "source": [
    "__Check__: Is $k(\\mathbf{x}_{i},\\mathbf{x}_{j})$ a valid kernel? For this kernel to be valid, the kernel matrix $\\mathbf{K}$ needs to be positive (semi)definite. Let's check the condition: $\\mathbf{x}^{\\top}\\,\\mathbf{K}\\,\\mathbf{x}\\geq{0}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "337b1592-991d-484e-943b-ef814c0b1c48",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `K` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `K` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[20]:2"
     ]
    }
   ],
   "source": [
    "let\n",
    "    number_of_rows = size(K,1);\n",
    "    x = randn(number_of_rows);\n",
    "    @assert transpose(x)*K*x ≥ 0\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ed30ea-32f4-4f7e-8028-562d548549ac",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Now that we have defined a kernel function, let's use it to classify our data. We've implemented a KNN classifier in this repo. In the code block below, we:\n",
    "* Construct [a `MyKNNClassificationModel` model](src/Types.jl) using a [custom `build(...)` method](src/Factory.jl). The `model` instance holds all the data for the problem, i.e., the how many neighbours to look at `K`, and the similarity function $d$.\n",
    "* Next, we pass this `model` instance to [the `classify(...)` method](src/Compute.jl) which takes a test feature $\\mathbf{z}$, the reference feature matrix $\\mathbf{X}$ and label vector $\\mathbf{y}$, and the classifier `model` instance and returns the predicted label value $\\hat{y}$ for the test feature vector $\\mathbf{z}$.\n",
    "* We return the predicted label in the `ŷ_KNN::Array{Int64,1}` array, and the actual label in the `y_KNN::Array{Int64,1}` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d0cdf87-4a2c-4f62-9fb2-eaf51a6ebddb",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[22]:4"
     ]
    }
   ],
   "source": [
    "ŷ_KNN,y_KNN, model = let\n",
    "\n",
    "    # Data -\n",
    "    D₁ = training; # reference dataset \n",
    "    D₂ = test; # test\n",
    "    number_of_training_examples = size(training,1);\n",
    "    number_of_test_examples = size(test,1);\n",
    "    X₁ = D₁[:,1:end-1]; # data for training (notice no extra 1)\n",
    "    y₁ = D₁[:,end]; # label for training\n",
    "    X₂ = D₂[:,1:end-1]; # data for test (notice no extra 1)\n",
    "    y₂ = D₂[:,end]; # label for test\n",
    "    ŷ₂ = zeros(number_of_test_examples);  # initialize some storage for the predicted label\n",
    "\n",
    "    # build a model -\n",
    "    model = build(MyKNNClassificationModel, (\n",
    "        K = 0, # TODO: update this with a non-zero ODD number (to break ties, undefined behavior in case of ties)\n",
    "        features = X₁, # Pass the feature reference data (refactored from lecture)\n",
    "        labels = y₁, # Pass the label references (refactored from lecture)\n",
    "        d = (x,y) -> k(x,y), # some distance or similarity metric (replace with (x,y) -> k(x,y) for a kernel)\n",
    "    ));\n",
    "\n",
    "    # process each vector in the test set, and compare that to training (reference)\n",
    "    for i ∈ 1:number_of_test_examples\n",
    "        z = X₂[i,:]; # get feature vector for test\n",
    "        ŷ₂[i] = classify(z,model) # classify the test vector using the training data (refactored from lecture)\n",
    "    end\n",
    " \n",
    "    # return -\n",
    "    ŷ₂,y₂,model\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67592fb-6bce-4f5b-a421-f1c3f45860e5",
   "metadata": {},
   "source": [
    "### Performance \n",
    "\n",
    "We can evaluate the binary classifier's performance using various metrics. The central idea is to compare the predicted labels $\\hat{y}_{i}$ to the actual labels $y_{i}$ in the `test` dataset and measure wins (when the label is the same) and losses (label is different). This is easily represented in [the confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix).\n",
    "* We compute confusion matrix [using the `confusion(...)` method](src/Compute.jl) and store it in the `CM_KNN::Array{Int64,2}` variable. The [`confusion(...)` method](src/Compute.jl) takes the actual labels and the computed labels and returns the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6923fe49-84db-48b0-a56d-d6c4c508bae2",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `y_KNN` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `y_KNN` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[24]:1"
     ]
    }
   ],
   "source": [
    "CM_KNN = confusion(y_KNN,ŷ_KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a709be-f557-474c-80a2-abb06b3cdfab",
   "metadata": {},
   "source": [
    "Finally, we can compute the overall error rate for the perceptron (or other performance metrics) using values from [the confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix). The [`confusion(...)` method](src/Compute.jl) takes the actual labels and the computed labels and returns the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b7eba7a-dc9a-40b5-937d-d4fffd7ed34b",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `y_KNN` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `y_KNN` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[26]:1"
     ]
    }
   ],
   "source": [
    "number_of_test_points = length(y_KNN);\n",
    "correct_prediction_perceptron = CM_KNN[1,1] + CM_KNN[2,2];\n",
    "(correct_prediction_perceptron/number_of_test_points) |> f-> println(\"Fraction correct: $(f) Fraction incorrect $(1-f)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b91ffc-cd4c-424c-a162-68beca5ea5b9",
   "metadata": {},
   "source": [
    "### Visualize the misses\n",
    "Using the `test` dataset, let's show (with white circles) which samples our classifier cannot predict the label correctly, i.e., where we miss the label. `Unhide` the code block below to see how we plotted the misclassified data points from the `test` dataset.\n",
    "* __Summary__: When there is a clear boundary, the [KNN classifier](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) misses along the borders between classes (even for non-linearly separable data). However, when the data is randomly arranged, the [KNN classifier](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) cannot correctly assign the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a033256-3876-4346-9e20-108ba0cd062b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `test` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nHint: a global variable of this name also exists in Pkg.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `test` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nHint: a global variable of this name also exists in Pkg.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[28]:3"
     ]
    }
   ],
   "source": [
    "let\n",
    "\n",
    "    dataset = test; # what dataset am I looking at?\n",
    "    caselabel = \"test\";\n",
    "    actual = y_KNN;\n",
    "    predicted = ŷ_KNN;\n",
    "    number_of_points = size(dataset,1); # number of rows\n",
    "    p = plot(bg=\"gray95\", background_color_outside=\"white\", framestyle = :box, fg_legend = :transparent); # make an empty plot\n",
    "    \n",
    "    # plot label = 1\n",
    "    testlabel = 1;\n",
    "    i = findfirst(label -> label == testlabel,  dataset[:,3])\n",
    "    c = my_color_dictionary[testlabel]\n",
    "    scatter!([dataset[i,1]], [dataset[i,2]], label=\"Label: $(testlabel)\", c=c)\n",
    "\n",
    "    # plot label = -1\n",
    "    testlabel = -1;\n",
    "    i = findfirst(label -> label == testlabel,  dataset[:,3])\n",
    "    c = my_color_dictionary[testlabel]\n",
    "    scatter!([dataset[i,1]], [dataset[i,2]], label=\"Label: $(testlabel)\", c=c)\n",
    "\n",
    "    # data -\n",
    "    for i ∈ 1:number_of_points\n",
    "        actuallabel = actual[i]; # actual label\n",
    "        testlabel = predicted[i]; # predited label\n",
    "\n",
    "        c = :white;\n",
    "        if (actuallabel == testlabel)\n",
    "            c = my_color_dictionary[actuallabel]\n",
    "        end\n",
    "        scatter!([dataset[i, 1]], [dataset[i, 2]], label=\"\", mec=:navy, c=c)\n",
    "    end\n",
    "\n",
    "    title!(\"KNN: $(caselabel)\", fontsize=18)\n",
    "    xlabel!(\"Feature 1 (AU)\", fontsize=18);\n",
    "    ylabel!(\"Feature 2 (AU)\", fontsize=18);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c8bcf4-7ac6-42ab-bc83-1db9c67d6e86",
   "metadata": {},
   "source": [
    "## Deeper: Let's look at the neighborhood of a feature\n",
    "When we get counterintuitive results, it is helpful to see what the classifier sees, i.e., look at the neighborhood used to estimate the label. Let's pick a feature vector index, compute its neighborhood set $\\mathcal{S}$, and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbb4cb12-613d-4905-9be4-9df6dc5abb70",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[30]:4"
     ]
    }
   ],
   "source": [
    "î,z,yz = let\n",
    "\n",
    "    # setup the data -\n",
    "    D₁ = training; # reference dataset \n",
    "    D₂ = test; # test\n",
    "    number_of_training_examples = size(training,1);\n",
    "    number_of_test_examples = size(test,1);\n",
    "    X₁ = D₁[:,1:end-1]; # data for training (notice no extra 1)\n",
    "    y₁ = D₁[:,end]; # label for training\n",
    "    X₂ = D₂[:,1:end-1]; # data for test (notice no extra 1)\n",
    "    y₂ = D₂[:,end]; # label for test \n",
    "\n",
    "    # get feature vector -\n",
    "    yz = 1;  # specify the label we want to see (1 = blue, -1 = orange)\n",
    "    i = findall(s-> s == yz, y₂) |> collect |> rand # use some logic to select a point (random point label = yz)\n",
    "\n",
    "    # Uncomment to see a misclassified point -\n",
    "    # ismislabeled = Array{Bool,1}()\n",
    "    # for i ∈ eachindex(ŷ_KNN)\n",
    "    #     if (ŷ_KNN[i] == y_KNN && y_KNN[i] == yz)\n",
    "    #         push!(ismislabeled,false)\n",
    "    #     else\n",
    "    #         push!(ismislabeled,true);\n",
    "    #     end\n",
    "    # end\n",
    "    # i = findfirst(s -> s==true,ismislabeled);\n",
    "    \n",
    "    \n",
    "    z = X₂[i,:]; # get the test feature\n",
    "    \n",
    "\n",
    "    # return\n",
    "    i,z,yz\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641904dd-2588-4c30-a71f-e36f7d79fec1",
   "metadata": {},
   "source": [
    "Find the neighborhood $\\mathcal{S}$: Each row containts the $(x,y)$ values, the label and the distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffe9163f-4bc1-45f7-9888-07f67b53ae7a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[32]:4"
     ]
    }
   ],
   "source": [
    "S = let\n",
    "\n",
    "    # data -\n",
    "    D₁ = training; # reference dataset \n",
    "    D₂ = test; # test\n",
    "    number_of_training_examples = size(training,1);\n",
    "\n",
    "    X₁ = D₁[:,1:end-1]; # data for training (notice no extra 1)\n",
    "    y₁ = D₁[:,end]; # label for training\n",
    "    X₂ = D₂[:,1:end-1]; # data for test (notice no extra 1)\n",
    "    y₂ = D₂[:,end]; # label for test\n",
    "    K = model.K;\n",
    "\n",
    "    # compute the distances to all other reference points\n",
    "    distances = zeros(number_of_training_examples);\n",
    "    for i ∈ 1:number_of_training_examples\n",
    "        xᵢ = X₁[i,:];\n",
    "        distances[i] = model.d(z,xᵢ);\n",
    "    end\n",
    "\n",
    "     # sort the distances \n",
    "    sorted_indices = sortperm(distances, rev=true);\n",
    "\n",
    "    # Get the top K points from the reference -\n",
    "    number_of_features = size(X₁,2) # data for training (notice no extra 1)\n",
    "    S = zeros(K,number_of_features+2)\n",
    "    for i ∈ 1:K\n",
    "        j = sorted_indices[i];\n",
    "        vᵢ = X₁[j,:];\n",
    "        yᵢ = y₁[j];\n",
    "        dᵢ = distances[j];\n",
    "\n",
    "        # package -\n",
    "        for k ∈ 1:number_of_features\n",
    "            S[i,k] = vᵢ[k]\n",
    "        end\n",
    "        S[i,number_of_features+1] = yᵢ\n",
    "        S[i,number_of_features+2] = dᵢ\n",
    "    end\n",
    "    S\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff597a6-b3b3-4d4d-9c1a-0031ccdf2fc4",
   "metadata": {},
   "source": [
    "Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e1f29f2-9ae3-42e1-9aaf-c27d1c7fe6d5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[34]:3"
     ]
    }
   ],
   "source": [
    "let\n",
    "\n",
    "    X₁ = training[:,1:end-1]; # data for training (notice no extra 1)\n",
    "    y₁ = training[:,end]; # label for training\n",
    "    \n",
    "    dataset = S[:,1:2];\n",
    "    y = S[:,3];\n",
    "    number_of_neighbor_points = size(dataset,1); # number of rows\n",
    "    number_of_training_points = size(X₁,1); # number of rows\n",
    "    \n",
    "    p = plot(bg=\"gray95\", background_color_outside=\"white\", framestyle = :box, \n",
    "        fg_legend = :transparent, xlims=(-3,3), ylims=(-3,3)); # make an empty plot\n",
    "\n",
    "\n",
    "    # plot all points -\n",
    "    for i ∈ 1:number_of_training_points\n",
    "        actuallabel = y₁[i]; # actual label\n",
    "        c = my_color_dictionary[actuallabel]\n",
    "        scatter!([X₁[i, 1]], [X₁[i, 2]], label=\"\", mec=:navy, c=c, alpha=0.1)\n",
    "    end\n",
    "      \n",
    "    # plot neighbors -\n",
    "    for i ∈ 1:number_of_neighbor_points\n",
    "        actuallabel = y[i]; # actual label\n",
    "        c = my_color_dictionary[actuallabel]\n",
    "        scatter!([S[i, 1]], [S[i, 2]], label=\"\", mec=:navy, c=c)\n",
    "    end\n",
    "    current()\n",
    "\n",
    "    # draw test point -\n",
    "    c = :yellow\n",
    "    scatter!([z[1]], [z[2]], label=\"true: $(yz) estimated: $(ŷ_KNN[î])\", c=c, ms=4)\n",
    "    \n",
    "    xlabel!(\"Feature 1 (AU)\", fontsize=18);\n",
    "    ylabel!(\"Feature 2 (AU)\", fontsize=18);\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
