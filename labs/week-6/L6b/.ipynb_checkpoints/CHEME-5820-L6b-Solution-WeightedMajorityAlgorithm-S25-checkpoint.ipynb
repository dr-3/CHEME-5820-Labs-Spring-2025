{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98014e43-2d68-406c-ab17-4ffe15a40673",
   "metadata": {},
   "source": [
    "# L6b: Implementation of the Weighted Majority Algorithm for Online Learning\n",
    "In this lab, we will implement and play with the Weighted Majority Algorithm online learning algorithm for a daily growth rate guessing game. Before we start, please review the Weighted Majority Algorithm.\n",
    "\n",
    "## Weighted Majority Algorithm\n",
    "Let's start with the Weighted Majority Algorithm developed by [Littlestone and Warmuth in 1994](https://www.sciencedirect.com/science/article/pii/S0890540184710091). We illustrate this approach with an example found in [Arora et al., 2005, Princeton](https://github.com/varnerlab/CHEME-5820-Lectures-Spring-2025/blob/main/lectures/week-6/L6a/docs/Arora-MWsurvey-CS-Princeton.pdf), which is a _prediction from expert advice_ problem. Let's take a look at the framing: \n",
    "\n",
    "* __Game__: The game's objective is to predict the daily stock price movement as either `up` or `down,` (which we encode as `{1 | -1}`). Each morning, we forecast the daily price direction, and by market close, we learn the actual movement. If we predict _incorrectly_, we lose a dollar. We aim to minimize losses. Our predictions are informed by the forecasts of $n$ experts, whose predictions may be correlated and accurate or not.\n",
    "* __Goal__: The weighted majority algorithm limits losses to about the best expert without knowing who that is until the end of the sequence. Each day, it requires decisions. The algorithm maintains a weighting of experts, initially giving them equal weight. Over time, those making better predictions have increased weight proportionately.\n",
    "\n",
    "We play this game between an omniscient _adversary_ (nature, i.e., the market) and an _aggregator_ (us) who $n$ experts advise; we select $n$ as odd to avoid ties. The game proceeds in rounds $t = 1, 2, \\ldots, T$. During each round the aggregator (us) makes a _binary_ decision $y_t \\in \\{-1, 1\\}$, and the adversary (market) reveals the true outcome $y_t$. Initially, the experts have weights $\\left\\{w_{i}^{(1)} = 1 \\mid i = 1, 2, \\ldots, n\\right\\}$. \n",
    "\n",
    "### Algorithm\n",
    "For each round $t=1,2,\\dots,T$:\n",
    "1. The aggregator (us) makes a prediction $y_t \\in \\{-1, 1\\}$ based on the weighted majority of the experts' predictions. If the total weight of all experts predicting `1` at time $t$ is $w^{(t)}\\geq\\sum_{i}w_{i}^{(t)}/2$, then the aggregator predicts `1`, otherwise it predicts `-1`.\n",
    "2. The adversary (market) reveals the actual outcome $y_t \\in \\{-1, 1\\}$.\n",
    "3. We decrease the weights of the experts who predicted incorrectly. For each expert $i$ who predicted incorrectly, we update the weight: $w_{i}^{(t+1)} = w_{i}^{(t)}(1-\\epsilon)$, where $0<\\epsilon\\leq{1/2}$ is a learning rate parameter.\n",
    "\n",
    "__Theorem__: The weighted majority algorithm has the following theoretical guarantee (which bounds the number of mistakes the aggregator makes). Let $m_{i}^{(t)}$ be the number of mistakes made by expert $i$ up to time $t$ and $m^{(t)}$ be the total number of mistakes made by the aggregator (us). Then, for every expert $i$ and the aggregator, we have:\n",
    "$$\n",
    "\\begin{align*}\n",
    "m^{(t)} \\leq \\frac{2\\ln(n)}{\\epsilon} + 2\\left(1+\\epsilon\\right)m_{i}^{(t)}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "### Tasks\n",
    "Before we start, divide into teams and familiarize yourself with the lab. Then, execute the `Run All Cells` command to check if you (or your neighbor) have any code or setup issues. Code issues, then raise your hands - and let's get those fixed!\n",
    "* __Task 1: Setup, Data, Constants (5 min)__: Let's take 5 minutes to explore the daily growth rate dataset for the components of the [SP500](https://en.wikipedia.org/wiki/S%26P_500).\n",
    "* __Task 2: Implement the Weighted Majority Algorithm (25 min)__: In this task, we'll implement a data-driven expert strategy in which we use (potentially) time-delayed growth rate data from other tickers to predict whether or not the [SPY 500 ETF `SPY`](https://en.wikipedia.org/wiki/SPDR_S%26P_500_ETF_Trust) will go up or down during a trading day.\n",
    "* __Task 3: Test the theoretical mistake bound (10 min)__: In this task, we'll test the theorem governing the upper bound on the number of mistakes an aggregator (us) will make relative to the system's experts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a7c5a9-33fe-4414-999e-10756ecc4017",
   "metadata": {},
   "source": [
    "## Task 1: Setup, Data, and Prerequisites\n",
    "We set up the computational environment by including the `Include.jl` file, loading any needed resources, such as sample datasets, and setting up any required constants. \n",
    "* The `Include.jl` file also loads external packages, various functions that we will use in the exercise, and custom types to model the components of our problem. It checks for a `Manifest.toml` file; if it finds one, packages are loaded. Other packages are downloaded and then loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb0d0fdd-7c9f-4133-8b7a-c48fde08d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598b3c24-2999-46e4-81bd-d4f5fdb90680",
   "metadata": {},
   "source": [
    "### Data\n",
    "We gathered a daily open-high-low-close `dataset` for each firm in the [S&P500](https://en.wikipedia.org/wiki/S%26P_500) from `01-03-2014` until `02-07-2025`, along with data for a few exchange-traded funds and volatility products during that time. We load the `orignal_dataset` by calling the `MyMarketDataSet()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16d23ad9-cbb2-4fe1-be8c-e141f15d9f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, DataFrame} with 515 entries:\n",
       "  \"TPR\"  => \u001b[1m1828×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  \"EMR\"  => \u001b[1m2792×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  \"CTAS\" => \u001b[1m2792×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  \"HSIC\" => \u001b[1m2792×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  \"KIM\"  => \u001b[1m2792×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  \"PLD\"  => \u001b[1m2792×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  \"IEX\"  => \u001b[1m2792×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  \"KSU\"  => \u001b[1m2001×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  \"BAC\"  => \u001b[1m2792×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  \"CBOE\" => \u001b[1m2792×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  \"EXR\"  => \u001b[1m2792×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  \"NCLH\" => \u001b[1m2792×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  \"CVS\"  => \u001b[1m2792×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  \"DRI\"  => \u001b[1m2792×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  \"DTE\"  => \u001b[1m2792×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  \"ZION\" => \u001b[1m2792×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  \"AVY\"  => \u001b[1m2792×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  \"EW\"   => \u001b[1m2792×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  \"EA\"   => \u001b[1m2792×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  \"NWSA\" => \u001b[1m2792×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  \"BBWI\" => \u001b[1m884×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  \"CAG\"  => \u001b[1m2792×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  \"GPC\"  => \u001b[1m2792×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  \"FCX\"  => \u001b[1m2792×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  \"GILD\" => \u001b[1m2792×8 DataFrame\u001b[0m\u001b[0m…\n",
       "  ⋮      => ⋮"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dataset = MyMarketDataSet() |> x-> x[\"dataset\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701dc726-0386-40ba-83b4-6d0ab6e0385d",
   "metadata": {},
   "source": [
    "__Clean the data__: Not all tickers in our dataset have the maximum number of trading days for various reasons, e.g., acquisition or de-listing events. Let's collect only those tickers with the maximum number of trading days.\n",
    "\n",
    "* First, let's compute the number of records for a company that we know has a maximum value, e.g., `AAPL`, and save that value in the `maximum_number_trading_days` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fd8abcf-3f31-49ed-a068-60752e473330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2792"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximum_number_trading_days = original_dataset[\"AAPL\"] |> nrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63284b1b-6114-4095-9587-ce85ca8594d0",
   "metadata": {},
   "source": [
    "Now, lets iterate through our data and collect only those tickers that have `maximum_number_trading_days` records. Save that data in the `dataset::Dict{String,DataFrame}` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fd922e9-0f8f-4c0b-b559-c9b1d80e4744",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = let\n",
    "\n",
    "    dataset = Dict{String,DataFrame}();\n",
    "    for (ticker,data) ∈ original_dataset\n",
    "        if (nrow(data) == maximum_number_trading_days)\n",
    "            dataset[ticker] = data;\n",
    "        end\n",
    "    end\n",
    "    dataset\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bb6f1b-38f5-4fca-877f-fa7e8581e160",
   "metadata": {},
   "source": [
    "Let's get a list of firms in the cleaned up `dataset` and save it in the `all_tickers` array. We sort the firms alphabetically from `A` to `Z`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67b2446a-789a-40a1-991d-4cc822eea7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424-element Vector{String}:\n",
       " \"A\"\n",
       " \"AAL\"\n",
       " \"AAP\"\n",
       " \"AAPL\"\n",
       " \"ABBV\"\n",
       " \"ABT\"\n",
       " \"ACN\"\n",
       " \"ADBE\"\n",
       " \"ADI\"\n",
       " \"ADM\"\n",
       " \"ADP\"\n",
       " \"ADSK\"\n",
       " \"AEE\"\n",
       " ⋮\n",
       " \"WST\"\n",
       " \"WU\"\n",
       " \"WY\"\n",
       " \"WYNN\"\n",
       " \"XEL\"\n",
       " \"XOM\"\n",
       " \"XRAY\"\n",
       " \"XYL\"\n",
       " \"YUM\"\n",
       " \"ZBRA\"\n",
       " \"ZION\"\n",
       " \"ZTS\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_all_tickers = keys(dataset) |> collect |> sort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7df88f8-c091-48ac-959f-66afe3cf4c75",
   "metadata": {},
   "source": [
    "Compute the expected (annualized) excess log growth rate by passing the `dataset` and the entire list of firms we have in the dataset to the [log_growth_matrix(...) method](src/Compute.jl). The log growth rate between time period $j-1$ to $j$, e.g., yesterday to today is defined as:\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mu_{j,j-1} = \\left(\\frac{1}{\\Delta{t}}\\right)\\ln\\left(\\frac{S_{j}}{S_{j-1}}\\right)\n",
    "\\end{equation}\n",
    "$$\n",
    "where $\\Delta{t}$ denotes the period time step, and $S_{j}$ denote share price in period $j$.\n",
    "* The log growth rates are stored in the `D::Array{Float64,2}` variable, a $T-1\\times{N}$ array of log return values. Each row of the `D` matrix corresponds to a time value, while each column corresponds to a firm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1881cfb8-6dd4-492f-b8eb-31677d42d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = let\n",
    "\n",
    "    # setup some constants -\n",
    "    Δt = (1/252); # 1-trading day in units of years\n",
    "    risk_free_rate = 0.0415; # inferred cc risk-free rate\n",
    "\n",
    "    # compute\n",
    "    μ = log_growth_matrix(dataset, list_of_all_tickers, Δt = Δt, \n",
    "        risk_free_rate = risk_free_rate);\n",
    "\n",
    "    μ # return to the caller\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44157a1b-d628-495c-83ee-c91362a11528",
   "metadata": {},
   "source": [
    "Next, let's [z-score center](https://en.wikipedia.org/wiki/Feature_scaling) the continous feature data. \n",
    "* In [z-score feature scaling](https://en.wikipedia.org/wiki/Feature_scaling), we subtract off the mean of each feature and then divide by the standard deviation, i.e., $x^{\\prime} = (x - \\mu)/\\sigma$ where $x$ is the unscaled data, and $x^{\\prime}$ is the scaled data. Under this scaling regime, $x^{\\prime}\\leq{0}$ will be values that are less than or equal to the mean value $\\mu$, while $x^{\\prime}>0$ indicate values that are greater than the mean.\n",
    "\n",
    "We save the z-score centered growth data in the `D̄::Array{Float64,2}` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9451668f-a62a-4165-92b9-3d290b39ffd3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2791×424 Matrix{Float64}:\n",
       " -0.270236    0.875241   -0.51285    …  -0.172603    0.0340086  -0.326599\n",
       "  0.735235    0.153683    0.270667       0.365351   -0.156963    0.235764\n",
       "  0.870466    0.123779    0.0157621     -0.0117454   0.206118   -0.771629\n",
       "  0.144598    2.39589     0.325758       0.018899    0.564557   -0.146732\n",
       "  0.462985    0.362567    0.624783       0.0834006  -0.405704    1.20044\n",
       "  0.135725   -0.543745   -0.130921   …  -0.192559   -0.35855    -0.922629\n",
       "  0.747335   -0.0617295   0.905321       0.29608    -0.334345   -0.35041\n",
       "  0.52576     0.145651    0.365443       0.279399    0.799572   -0.0816769\n",
       "  0.326013    0.237151    0.0344876     -0.312346   -0.399924    0.363208\n",
       "  0.30077     0.854261    0.186164      -0.316981    0.513302   -0.448288\n",
       " -0.150497    0.679814    0.199977   …  -0.0918959   1.72074    -0.892273\n",
       "  0.339601    0.505721   -0.416694       0.0999343   0.812754    0.0533844\n",
       " -1.32135     0.197223   -0.539546      -0.432322   -1.22161     0.354251\n",
       "  ⋮                                  ⋱                          \n",
       " -0.420465   -2.97196     0.850221      -0.337995   -0.141436   -0.248732\n",
       " -0.0395886  -0.216563    0.683655   …  -0.471825    0.380037    0.697634\n",
       " -0.488413    0.439841    0.83359       -1.76867    -0.495274    1.69459\n",
       "  0.221058   -0.0251536  -0.23056        0.0508272  -0.325489   -0.246398\n",
       " -1.73696    -0.0879981   0.18514       -0.109855    0.137812   -0.611184\n",
       "  1.68952    -0.433526    0.903164      -0.532549    0.475246    1.19216\n",
       "  0.361025    0.205188   -1.04797    …  -0.18947    -0.328673   -0.759341\n",
       " -1.50238    -0.932005   -0.763702      -1.29046    -1.37594     0.118333\n",
       " -0.877171    0.488268    1.61299       -0.011034    0.640157    0.0649832\n",
       "  0.368773    0.27262    -0.281018       0.260768    0.15311     1.18247\n",
       " -0.20762     0.262206    0.0101682     -1.02258     0.608967   -0.0053034\n",
       " -0.775666    0.374822   -2.62881    …  -1.92793    -0.593067   -1.25676"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D̄ = let\n",
    "\n",
    "    # setup -\n",
    "    number_of_examples = size(D,1);\n",
    "\n",
    "    D̄ = copy(D);\n",
    "    for j ∈ eachindex(list_of_all_tickers)\n",
    "        μ = mean(D[:,j]); # compute the mean\n",
    "        σ = std(D[:,j]); # compute std\n",
    "\n",
    "        # rescale -\n",
    "        for k ∈ 1:number_of_examples\n",
    "            D̄[k,j] = (D[k,j] - μ)/σ;\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    D̄\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51392542-26bb-4c0e-80cc-f916a1e45382",
   "metadata": {},
   "source": [
    "Next, let's set up a ticker map that holds the index of each ticker value. We'll save this in the `tickerindexmap::Dict{String,Int}` dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "665cab5d-4947-4405-892e-a8f3aa8f13aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Int64} with 424 entries:\n",
       "  \"EMR\"  => 132\n",
       "  \"CTAS\" => 101\n",
       "  \"HSIC\" => 187\n",
       "  \"KIM\"  => 217\n",
       "  \"PLD\"  => 310\n",
       "  \"IEX\"  => 194\n",
       "  \"BAC\"  => 48\n",
       "  \"CBOE\" => 69\n",
       "  \"EXR\"  => 144\n",
       "  \"NCLH\" => 271\n",
       "  \"CVS\"  => 103\n",
       "  \"DRI\"  => 119\n",
       "  \"DTE\"  => 120\n",
       "  \"ZION\" => 423\n",
       "  \"AVY\"  => 43\n",
       "  \"EW\"   => 140\n",
       "  \"EA\"   => 124\n",
       "  \"NWSA\" => 289\n",
       "  \"CAG\"  => 65\n",
       "  \"GILD\" => 161\n",
       "  \"FCX\"  => 148\n",
       "  \"GPC\"  => 168\n",
       "  \"UNP\"  => 390\n",
       "  \"CDW\"  => 73\n",
       "  \"SBUX\" => 339\n",
       "  ⋮      => ⋮"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickerindexmap = let\n",
    "\n",
    "    # initialize -\n",
    "    tickerindexmap = Dict{String,Int}();\n",
    "    for i ∈ eachindex(list_of_all_tickers)\n",
    "        tickerindexmap[list_of_all_tickers[i]] = i;\n",
    "    end\n",
    "\n",
    "    tickerindexmap;\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf3eda8-67a5-43e3-a2c9-04817bca07d7",
   "metadata": {},
   "source": [
    "## Task 2: Implement the Weighted Majority Algorithm\n",
    "In this task, we'll implement a data-driven expert strategy in which we use (potentially) time-delayed growth rate data from other tickers to predict whether or not the [SPY 500 ETF `SPY`](https://en.wikipedia.org/wiki/SPDR_S%26P_500_ETF_Trust) will go up or down during a trading day.\n",
    "\n",
    "First, we'll define the `expert` and `adversary` functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef48f4c-55b8-418b-8b13-fa403a533eee",
   "metadata": {},
   "source": [
    "* The `expert(index::Int, time::Int, data::Array{Float64,2})::Int` function takes the `index::Int` of the expert, the current time step `t::Int` and the market `data::Array{Float64,2})` array which is the _actual_ growth rate data `D̄`. This function returns the _prediction_ from expert $i$, namely $y_{t}^{(i)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "636eb311-46b6-475d-aff1-37d0d22de8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "function expert(index::Int, time::Int, data::Array{Float64,2})::Int\n",
    "\n",
    "    # These are my choices for experts: you pick yours\n",
    "    # expert 1: QQQ\n",
    "    # expert 2: NVDA\n",
    "    # expert 3: AMD\n",
    "    # expert 4: AAPL\n",
    "    # expert 5: MSFT\n",
    "    \n",
    "    i = nothing;\n",
    "    if (index == 1)\n",
    "        i = tickerindexmap[\"WMT\"];\n",
    "    elseif (index == 2)\n",
    "        i = tickerindexmap[\"TGT\"];\n",
    "    elseif (index == 3)\n",
    "        i = tickerindexmap[\"MRK\"];\n",
    "    elseif (index == 4)\n",
    "        i = tickerindexmap[\"JNJ\"];\n",
    "    elseif (index == 5)\n",
    "        i = tickerindexmap[\"AAPL\"];\n",
    "    end\n",
    "    return data[time+1,i] |> sign;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f249a176-3316-4dfc-82e2-5f0e44fa4699",
   "metadata": {},
   "source": [
    "* The `adversary(time::Int, data::Array{Float64,2})::Int` function takes the current time step `t::Int` and the market `data::Array{Float64,2})` array and returns the true answer $y_{t}$ for the `SPY` growth rate for time $t$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bc9e889-2a87-4703-9713-97cabb4bf694",
   "metadata": {},
   "outputs": [],
   "source": [
    "function adversary(time::Int, data::Array{Float64,2})::Int\n",
    "\n",
    "    # adversary is SPY -\n",
    "    result = tickerindexmap[\"SPY\"] |> i-> data[time,i] |> sign;\n",
    "    return result\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5062c81e-254a-4862-89a2-7fb4160e6b5f",
   "metadata": {},
   "source": [
    "Next, we'll build [a `model::MyBinaryWeightedMajorityAlgorithmModel` instance](src/Types.jl) that holds all the data associated with the problem [using a `build(...)` method](src/Factory.jl). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d092bfad-0b59-4e32-bb30-b3173bf5afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = let\n",
    "\n",
    "    # build -\n",
    "    model = build(MyBinaryWeightedMajorityAlgorithmModel, (\n",
    "        ϵ = 0.49, # learning rate \n",
    "        n = 5, # number of experts (needs to be odd to avoid ties)\n",
    "        T = 252, # number of rounds\n",
    "        expert = expert, # expert function\n",
    "        adversary = adversary, # adversary function\n",
    "    ));\n",
    "\n",
    "    # return the model -\n",
    "    model;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bdac87-0d51-4bcf-ad6d-4caa4c2b8628",
   "metadata": {},
   "source": [
    "Finally, we call [the `play(...)` method](src/Online.jl) to run the simulation. The [`play(...)` method](src/Online.jl) takes the `model::MyBinaryWeightedMajorityAlgorithmModel` instance and the data matrix `D̄::Array{Float64,2}` and returns two arrays:\n",
    "* The `sims::Array{Float64,2}` holds simulation information. Each row corresponds to a time `t.` The first $n$ columns correspond to the predictions of experts $i=1,2,\\dots,n$ at a time `t.` Column $n+1$ corresponds to the aggregator (us) prediction, and column $n+2$ corresponds to the adversary prediction at time `t.` Finally, the last column holds the loss value $l_{t}$ for the aggregator.\n",
    "* The `weights::Array{Float64,2}` array holds the weights for each expert in our system. The rows of this array correspond to the timesteps `t`, while each column holds the $w_{i}^{(t)}$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c911a2d1-93a3-4cf4-a858-81a54754eb6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "KeyError: key \"MRNA\" not found",
     "output_type": "error",
     "traceback": [
      "KeyError: key \"MRNA\" not found",
      "",
      "Stacktrace:",
      " [1] getindex(h::Dict{String, Int64}, key::String)",
      "   @ Base ./dict.jl:477",
      " [2] expert(index::Int64, time::Int64, data::Matrix{Float64})",
      "   @ Main ./In[20]:20",
      " [3] play(model::MyBinaryWeightedMajorityAlgorithmModel, data::Matrix{Float64})",
      "   @ Main ~/Desktop/julia_work/CHEME-5820-SP25/CHEME-5820-Labs-Spring-2025/labs/week-6/L6b/src/Online.jl:34",
      " [4] top-level scope",
      "   @ In[26]:1"
     ]
    }
   ],
   "source": [
    "(sims, weights) = play(model, D̄);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06440396-3434-433e-a1c0-305a1cacb4c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `sims` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `sims` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      ""
     ]
    }
   ],
   "source": [
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38eb7846-174c-4a02-ab50-1cb389be30a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `sims` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `sims` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[28]:1"
     ]
    }
   ],
   "source": [
    "findall(x-> x == 0, sims[:,end]) |> i-> length(i)/252"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b46e20-4a78-455f-ad55-89c4e279969e",
   "metadata": {},
   "source": [
    "`Unhide` the code block below to see how we plotted the weights versus $t$ for the experts in our system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2730109b-45c1-446b-afcf-a55f09faa0bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `weights` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nHint: a global variable of this name may be made accessible by importing StatsBase in the current active module Main",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `weights` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nHint: a global variable of this name may be made accessible by importing StatsBase in the current active module Main",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[30]:3"
     ]
    }
   ],
   "source": [
    "let\n",
    "    p = plot(bg=\"gray95\", background_color_outside=\"white\", framestyle = :box, fg_legend = :transparent); \n",
    "    plot!(weights[:,1], c=:deepskyblue1, lw=2, label=\"expert 1\")\n",
    "    plot!(weights[:,2],c=:navy, lw=2, label=\"expert 2\")\n",
    "    plot!(weights[:,3],c=:red, lw=2, label=\"expert 3\")\n",
    "    plot!(weights[:,4],c=:darkorange, lw=2, label=\"expert 4\")\n",
    "    plot!(weights[:,5],c=:magenta, lw=2, label=\"expert 5\")\n",
    "    xlabel!(\"Time step t (day)\", fontsize=18)\n",
    "    ylabel!(\"Weight (AU)\", fontsize=18)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022fc240-a101-469d-a28f-8b1b7448eb74",
   "metadata": {},
   "source": [
    "## Task 3: Test the theoretical mistake bound\n",
    "In this task, we'll test the theorem governing the upper bound on the number of mistakes an aggregator (us) will make relative to the system's experts.\n",
    "\n",
    "__Theorem__: The weighted majority algorithm has the following theoretical guarantee (which bounds the number of mistakes the aggregator makes). Let $m_{i}^{(t)}$ be the number of errors made by expert $i$ up to time $t$ and $m^{(t)}$ be the total number of errors made by the aggregator (us) up to time $t$. Then, for every expert $i$ and the aggregator, we have:\n",
    "$$\n",
    "\\begin{align*}\n",
    "m^{(t)} \\leq \\frac{2\\ln(n)}{\\epsilon} + 2\\left(1+\\epsilon\\right)m_{i}^{(t)}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Let's start by identifying the best expert in hindsight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7183b739-7b96-4eee-b0e9-12d34cabff63",
   "metadata": {},
   "source": [
    "__Which expert was best__? Let's use the _heuristic_ that the best expert will be the one with the highest weight at the end of the game, i.e., $\\hat{i} = \\text{arg}\\max\\left(w_{1}^{(T)},w_{2}^{(T)},\\dots,w_{n}^{(T)}\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1638bf19-e0ec-4884-9eba-cb547123641e",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `weights` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nHint: a global variable of this name may be made accessible by importing StatsBase in the current active module Main",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `weights` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nHint: a global variable of this name may be made accessible by importing StatsBase in the current active module Main",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[33]:1"
     ]
    }
   ],
   "source": [
    "î = argmax(weights[end,:]) # index of the largest weight at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48184e5-a43f-4833-a702-3814c3bad1e3",
   "metadata": {},
   "source": [
    "Next, we'll compute the number of mistakes by our experts as a function of time $t$. We'll save this in the `m_experts::Array{Int64,2}` array where each row corresponds to a time index $t$, and each column is loss suffered by each expert. \n",
    "* In this case, if the expert was _incorrect_ they have a loss of `1`; otherwise, they have a loss of `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c0f7018-8407-446d-8529-ca1ab63cd330",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `sims` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `sims` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[35]:10"
     ]
    }
   ],
   "source": [
    "m_experts = let\n",
    "\n",
    "    # data -\n",
    "    n = model.n; # number of experts\n",
    "    T = model.T; # number of rounds in the game\n",
    "    m = Array{Int64,2}(undef, T, n);\n",
    "\n",
    "    for t ∈ 1:T\n",
    "        for j ∈ 1:n\n",
    "            expert_prediction = sims[t,j];\n",
    "            adversary_prediction = sims[t,end-1]; # adv is the penultimate column\n",
    "            m[t,j] = expert_prediction == adversary_prediction ? 0 : 1\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # return \n",
    "    m\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae64ec8-89c4-4ecf-8ad0-2115538b601d",
   "metadata": {},
   "source": [
    "### Compute the bound\n",
    "Finally, let's compute the bound. We save the left side of the bound (the aggregator term) in the `L::Array{Float64,1}` variable, while the right side is saved in the `R::Array{Float64,1}` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "658222f2-35f8-499b-b025-8beaab8401a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `sims` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `sims` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ ./In[37]:9"
     ]
    }
   ],
   "source": [
    "L,R = let\n",
    "\n",
    "    # data -\n",
    "    n = model.n; # number of experts\n",
    "    T = model.T; # number of rounds in the game\n",
    "    ϵ = model.ϵ; # Get the learning rate\n",
    "    L = Array{Float64,1}(undef, T); # left term\n",
    "    R = Array{Float64,1}(undef, T); # right term\n",
    "    m_aggregartor = sims[:,end]; # aggregator mistakes on the last column\n",
    "    m_expert = m_experts[:,î]; # best expert\n",
    "\n",
    "    # compute the left term L\n",
    "    for t ∈ 1:T\n",
    "        L[t] = sum(m_aggregartor[1:t]);\n",
    "    end\n",
    "    \n",
    "    # compute the right term R\n",
    "    for t ∈ 1:T\n",
    "        R[t] = (2*log(n)/ϵ) + 2*(1+ϵ)*sum(m_expert[1:t])\n",
    "    end\n",
    "    \n",
    "    L,R\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ceaaa8-2a60-40f8-9093-3bfb39103637",
   "metadata": {},
   "source": [
    "`Unhide` the code block below to see how we plotted the `L` and `R` components of the theoretical bound expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4960b129-ff91-4d4a-8e79-b433c3a77cfb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `L` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `L` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[39]:3"
     ]
    }
   ],
   "source": [
    "let\n",
    "    p = plot(bg=\"gray95\", background_color_outside=\"white\", framestyle = :box, fg_legend = :transparent);\n",
    "    plot!(L, c=:navy, lw=2, label=\"Left (aggregator)\")\n",
    "    plot!(R, c=:red, lw=2, label=\"Right (expert)\")\n",
    "    xlabel!(\"Time step t (day)\", fontsize=18)\n",
    "    ylabel!(\"Mistakes (AU)\", fontsize=18)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
