{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "badef201-7a31-4158-a419-ffe0f5447e5e",
   "metadata": {},
   "source": [
    "# L6d: Multiplicative Weight Update Algorithm for Linear Programs\n",
    "In this lab, we'll use a variant of the [Multiplicative Weight Update Algorithm](https://en.wikipedia.org/wiki/Multiplicative_weight_update_method) to (approximately) solve a [linear programming problem](https://en.wikipedia.org/wiki/Multiplicative_weight_update_method#Solving_linear_programs_approximately[14]). \n",
    "Let $\\Delta_{m} = \\{\\mathbf{x} \\in \\mathbb{R}_{\\geq{0}}^{m} \\mid \\sum_{i=1}^{m}x_{i} = \\tau\\}$ be a set of $m$-dimensional vectors with non-negative entries that sum to $\\tau$. \n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{Find} &\\quad \\mathbf{x} \\in \\Delta_{m} \\\\\n",
    "\\text{subject to} &\\quad \\mathbf{A}\\mathbf{x} \\leq \\mathbf{b}\n",
    "\\end{align*}\n",
    "$$\n",
    "This formulation may seem restrictive, but we can convert _most_ linear programs into this form. We will use the Multiplicative Weight Update algorithm to solve the following problem. There is a famous (Cornell) Multiplicative Weight Update algorithm to solve this problem:\n",
    "* [Plotkin, Serge A., et al. “Fast Approximation Algorithms for Fractional Packing and Covering Problems.” Mathematics of Operations Research, vol. 20, no. 2, 1995, pp. 257–301](https://www.jstor.org/stable/3690406?socuuid=57de56c3-135d-4376-9af5-be0257a4c2d8)\n",
    "\n",
    "but we will use our own implementation [inspired by a lecture by Prof. Saranurak at the University of Michigan](https://www.youtube.com/watch?v=5u8wYZjsHuc&t=3190s).\n",
    "\n",
    "\n",
    "### Algorithm\n",
    "__Initialize__: We have $m$ experts (one for each unknown $x_{i}$) and $T$ rounds. Each expert $i$ has a weight $w_{i}^{(t)}$ at round $t$. The weights are initialized to $w_{i}^{(1)}=1$ for all experts. We specify a learning rate $\\eta\\in{(0,1)}$. The constraint matrix $\\mathbf{A}\\in\\left[-\\rho,\\rho\\right]^{n\\times{m}}$ and $\\mathbf{b}\\in\\mathbb{R}^{m}$.\n",
    "\n",
    "For each round $t=1,2,\\dots,T$ where the number of rounds is $T = \\ln({m})/\\epsilon^{2}$:\n",
    "1. The aggregator (us) computes a candidate solution $x_{i}^{(t)} = \\tau\\left(w_{i}^{(t)}/\\Phi^{(t)}\\right)$ from the weight of each expert $i$, where $\\Phi^{(t)} = \\sum_{i=1}^{m}w_{i}^{(t)}$.\n",
    "2. The aggregator (us) computes the associated constraint violation (loss) $\\mathbf{r} = \\mathbf{A}\\mathbf{x}^{(t)} - \\mathbf{b} -2\\epsilon\\mathbf{I}$. If all $\\{r_{i} \\leq 0 \\mid i = 1,2,\\dots,n\\}$ we have a feasible solution. We return $\\mathbf{x}^{(t)}$ and `true.` Otherwise, if _any_ elements $\\{r_{i}>0 \\mid i = 1,2,\\dots,n\\}$ we update the weights of the experts.\n",
    "3. For each violated constraint $k\\in\\left[n\\right]$, i.e., $\\{k\\}$ are the indexed with $r_{i}>0$, we update the weights of _all experts_ using the update rule:\n",
    "$$\n",
    "\\begin{align*}\n",
    "w_{j}^{(t+1)} = w_{j}^{(t)}\\cdot\\left(1-\\eta\\cdot{a_{k,j}}\\right) \\quad j = 1,2,\\dots,m\n",
    "\\end{align*}\n",
    "$$\n",
    "4. Go to step 1. We iterate until we find a solution that satisfies all constraints, or we run out of rounds. If we run out of rounds without finding a solution, we return `false,` which says our problem formulation is infeasible.\n",
    "\n",
    "If the problem is feasible, this approach will converge to a solution $\\mathcal{O}((\\dim\\mathbf{A}_{\\neq{0}})\\cdot\\ln(m)\\cdot(\\rho\\tau/\\epsilon)^{2})$\n",
    "\n",
    "### Tasks\n",
    "Before we start, divide into teams and familiarize yourself with the lab. Then, execute the `Run All Cells` command to check if you (or your neighbor) have any code or setup issues. Code issues, then raise your hands - and let's get those fixed!\n",
    "* __Task 1: Setup, Data, Prerequisites (10 min)__: Let's take 10 minutes to set up the problem and, in particular, look at the graph we will explore.\n",
    "* __Task 2: Set up the problem model and play the game (20 min)__: In this task, we'll set up and solve the linear programming problem. First, we'll build an [instance of the `MyConstraintCheckingGameModel` type](src/Types.jl) containing information about the problem. Then, we'll solve the problem and think about the results.\n",
    "* __Task 3: Check and analyze the results (10 min)__: In this task, we analyze the results produced by our approach. First, we check the bounds for constraint violations and then examine the solution to see if it makes sense (and what the algorithm returns). We'll start with the bounds and then consider the properties of the flow vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5b4689-258b-4c5a-989c-6ed9d39c5f17",
   "metadata": {},
   "source": [
    "## Task 1: Setup, Data, and Prerequisites\n",
    "We set up the computational environment by including the `Include.jl` file, loading any needed resources, such as sample datasets, and setting up any required constants. \n",
    "* The `Include.jl` file also loads external packages, various functions that we will use in the exercise, and custom types to model the components of our problem. It checks for a `Manifest.toml` file; if it finds one, packages are loaded. Other packages are downloaded and then loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d4ad877-c4ee-423d-b4b2-82940b6f3a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74f2c71-d685-4344-b967-b95a3b3fad2c",
   "metadata": {},
   "source": [
    "### Graph model \n",
    "\n",
    "We'll represent the network we will explore as the graph $\\mathcal{G}=\\left(\\mathcal{V},\\mathcal{E}\\right)$ which we model as [an instance of the `MySimpleDirectedGraphModel` type](src/Types.jl). We create our graph model from an [Edge list representation](https://en.wikipedia.org/wiki/Edge_list). \n",
    "* In the [Edge list representation](https://en.wikipedia.org/wiki/Edge_list), only the edge information is stored (typically) in a comma-separated value (CSV) file in which each record holds an edge in the graph, and the fields contain `source, target, ....` data for each edge.\n",
    "* We've used [the `readedgesfile(...)` function in `src/Files.jl`](src/Files.jl) to build a list of edges in our graph, where each edge is an instance of [the `MyGraphEdgeModel` type](src/Types.jl) which holds edge information.\n",
    "* We can then pass the edge list to [a `build(...)` method](src/Factory.jl) for our graph model, the populated `graphmodel::MySimpleDirectedGraphModel` is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef59f6a5-d008-4303-a453-f5717d188365",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphmodel = let\n",
    "\n",
    "    # load up the balanced example -\n",
    "    balanced_edgefile = joinpath(_PATH_TO_DATA, \"Network.edgelist\");\n",
    "    balanced_graphmodel = readedgesfile(balanced_edgefile) |> edges -> build(MySimpleDirectedGraphModel, edges);\n",
    "\n",
    "    balanced_graphmodel\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503d4bdc-b950-4001-a264-7ea72fb1c54f",
   "metadata": {},
   "source": [
    "What's in the `graphmodel::MySimpleDirectedGraphModel` instance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ff0411c-0d32-4156-a666-7aaf584251d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×6 Matrix{Float64}:\n",
       " -1.0  -1.0  -1.0   0.0   0.0   0.0\n",
       "  1.0   0.0   0.0  -1.0   0.0   0.0\n",
       "  0.0   1.0   0.0   0.0  -1.0   0.0\n",
       "  0.0   0.0   1.0   0.0   0.0  -1.0\n",
       "  0.0   0.0   0.0   1.0   1.0   1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphmodel.A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4745a297-2a23-4130-97d6-b279f4532b19",
   "metadata": {},
   "source": [
    "### Constants and other parameters\n",
    "Before solving the linear program, we need to specify a number of items. Let's begin with how much error we are willing to live with, and then we'll move on to the components of the constraints $\\mathbf{A}\\mathbf{x}\\leq\\mathbf{b}$.\n",
    "\n",
    "Let's start with the tolerance parameter `ϵ::Float64`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c962b909-2df4-45d5-ab5f-b2921a090ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ϵ = 0.01; # we willing to live with a 2ϵ violation of *every* constraint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab83f1a-287f-4f99-abf2-e0fb07944da7",
   "metadata": {},
   "source": [
    "Next, let's specify the matrix $\\mathbf{A}\\in\\mathbb{R}^{n\\times{m}}$ and the right-hand side vector $\\mathbf{b}\\in\\mathbb{R}^{n}$.\n",
    "\n",
    "The constraint matrix $\\mathbf{A}$ is [the incidence matrix of our graph $\\mathcal{G}$]( https://en.wikipedia.org/wiki/Incidence_matrix). The incidence matrix of a directed graph is a $n\\times{m}$ matrix $\\mathbf{A}$ where n and m are the number of vertices and edges, respectively, such that:\n",
    "$$\n",
    "\\begin{equation}\n",
    "a_{ij} = \\begin{cases}\n",
    "-1 & \\text{if edge}\\,e_{j}\\,\\text{leaves vertex}\\,v_{i}\\\\\n",
    "1 & \\text{if edge}\\,e_{j}\\,\\text{enters vertex}\\,v_{i}\\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "The incidence matrix was already constructed for us when we built the `graphmodel::MySimpleDirectedGraphModel` instance; it is stored in the `A` field of the graph model.\n",
    "\n",
    "The right-hand side vector $\\mathbf{b}\\in\\mathbb{R}^{n}$ holds the right side of the inequalities. We'll set a default of `0` and then adjust the entries for different problems (or when we are playing with the hyperparameters of the approach)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82edf9fc-e50b-4314-bedb-c579e5516ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, b = let\n",
    "\n",
    "    A = graphmodel.A # let's get A\n",
    "    n = size(A,1); # number of nodes (rows)\n",
    "    m = size(A,2); # number of edges (cols)\n",
    "    \n",
    "    # right-hand side -\n",
    "    b = zeros(n); # number of nodes\n",
    "    b[1] = -1.0;\n",
    "    b[2] = 0.0;\n",
    "    b[end] = 1.0\n",
    "\n",
    "    A,b\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd285389-3988-42f6-bfdd-07288bbfec40",
   "metadata": {},
   "source": [
    "## Task 2: Set up the problem model and play the game.\n",
    "In this task, we'll set up and solve the linear programming problem. First, let's build an [instance of the `MyConstraintCheckingGameModel` type](src/Types.jl) containing information about the problem. Then, we'll solve the problem and think about the results.\n",
    "\n",
    "The [`MyConstraintCheckingGameModel` type](src/Types.jl) has several fields related to the problem. To construct this type, we pass the type of thing we want to construct and information about the problem to [a `build(...)` method](src/Factory.jl). This returns the populated model in the `model::MyConstraintCheckingGameModel` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10a09a5f-5ce2-4c14-a7bc-d0f9fcb40c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = let\n",
    "\n",
    "    # get data from the graph model -\n",
    "    A = graphmodel.A; # constraint matrix\n",
    "    n = size(A,1); # number of nodes (constraints)\n",
    "    m = size(A,2); # number of edges (variables)\n",
    "    T = log(m)/(ϵ^2) |> x-> round(Int,x) # number of time steps\n",
    "\n",
    "    # build the problem model -\n",
    "    model = build(MyConstraintCheckingGameModel, (\n",
    "        η = 0.05, # learning rate\n",
    "        T = T, # max number of time steps\n",
    "        A = A, # constraint matrix\n",
    "        b = b, # right-hand side vector\n",
    "        ρ = 1.0, # max element in A (scale: [-ρ,ρ])\n",
    "        τ = 2.0, # sum of x\n",
    "    ));\n",
    "\n",
    "    # return -\n",
    "    model;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d05f40-2f46-45f5-94be-9864cb3bbe2d",
   "metadata": {},
   "source": [
    "### Play the game \n",
    "\n",
    "To play the game, i.e., to solve the linear programming problem, we pass the `model::MyConstraintCheckingGameModel` instance and our tolerance value `ϵ::Float64` to [the `play(...)` method](src/Online.jl). This method returns several pieces of data that are interesting:\n",
    "* The $\\mathbf{x}\\in\\mathbb{R}^{m}$ vector is the best solution found for the problem; we store this in the `x::Array{Float64,1}` variable.\n",
    "* The `flag::Bool = {true | false}` variable tells us where or not the aggregator (us) found a solution (or ran out of iterations).\n",
    "* Finally, the `w::Array{Float64,2}` variable holds the weight matrix, where each row is an iteration, and the columns correspond to the weight of expert $i$ (one expert per variable).\n",
    "\n",
    "However, before we move on to the next task, we check convergence [using the `@assert` macro](https://docs.julialang.org/en/v1/base/base/#Base.@assert). If the aggregator (us) fails to find a solution, [an `AssertionError` is thrown](https://docs.julialang.org/en/v1/base/base/#Core.AssertionError)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8144c3cf-85a5-4bd6-85c7-5ca4e0be9135",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,flag,w = play(model, ϵ = ϵ);\n",
    "@assert flag == true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e126014-2038-4e35-bdb0-6e7594fe7903",
   "metadata": {},
   "source": [
    "## Task 3: Check and analyze the results\n",
    "In this task, we analyze the results produced by our approach. First, we check the bounds for constraint violations and then look at the solution to see if it makes sense (and what the algorithm returned). Let's start with the bounds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c4a648-60e7-497f-99a4-7735897546bc",
   "metadata": {},
   "source": [
    "### Bounds table \n",
    "`Unhide` the code block below to see the residual that the algorithm produced for each constraint $r_{i} = \\sum_{j}a_{ij}x_{j} - b_{i}$, the specified residual $b_{i}$ and whether the constraint was violated.\n",
    "* __Summary__: If the constraint was violated, then `flag = false,` so we should have seen [an `AssertionError`](https://docs.julialang.org/en/v1/base/base/#Core.AssertionError). Otherwise $r_{i}\\leq{b}_{i}\\,\\forall{i}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65d9b0ec-89cb-4614-a3fd-c803740c7a1b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== ========= ========= =============\n",
      " \u001b[1m  node \u001b[0m \u001b[1m      rᵢ \u001b[0m \u001b[1m      bᵢ \u001b[0m \u001b[1m violationᵢ \u001b[0m\n",
      " \u001b[90m Int64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m Float64 \u001b[0m \u001b[90m       Bool \u001b[0m\n",
      "======== ========= ========= =============\n",
      "      1      -1.0      -1.0        false\n",
      "      2       0.0       0.0        false\n",
      "      3       0.0       0.0        false\n",
      "      4       0.0       0.0        false\n",
      "      5       1.0       1.0        false\n",
      "======== ========= ========= =============\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "    df = DataFrame();\n",
    "    r₁ = A*x;\n",
    "\n",
    "    for i ∈ eachindex(r₁)\n",
    "        value = r₁[i];\n",
    "        row_df = (\n",
    "            node = i,\n",
    "            rᵢ = value,\n",
    "            bᵢ = b[i],\n",
    "            violationᵢ = (value - b[i]) > 2*ϵ ? true : false\n",
    "        );\n",
    "        push!(df, row_df);\n",
    "    end\n",
    "\n",
    "    pretty_table(df, tf = tf_simple)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28ece27-cd80-4c33-ade5-bd904aed4d88",
   "metadata": {},
   "source": [
    "### Edge table\n",
    "`Unhide` the code block below to see the value for the flow carried on each edge of our graph $\\mathcal{G}$.\n",
    "* __Summary__: The sum of the flows should be: $\\sum_{j}x_{j} = \\tau$. We check the summation condition below [using the `@assert` macro](https://docs.julialang.org/en/v1/base/base/#Base.@assert). If the summation condition is violated [an `AssertionError` is thrown](https://docs.julialang.org/en/v1/base/base/#Core.AssertionError)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eecf3c6e-9343-4eb0-9d31-0d47075a8345",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== ======= ======= ===========\n",
      " \u001b[1m  edge \u001b[0m \u001b[1m start \u001b[0m \u001b[1m  stop \u001b[0m \u001b[1m     flow \u001b[0m\n",
      " \u001b[90m Int64 \u001b[0m \u001b[90m Int64 \u001b[0m \u001b[90m Int64 \u001b[0m \u001b[90m  Float64 \u001b[0m\n",
      "======== ======= ======= ===========\n",
      "      1       1       2   0.333333\n",
      "      2       1       3   0.333333\n",
      "      3       1       4   0.333333\n",
      "      4       2       5   0.333333\n",
      "      5       3       5   0.333333\n",
      "      6       4       5   0.333333\n",
      "======== ======= ======= ===========\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "\n",
    "    ei = graphmodel.edgesinverse;\n",
    "    df = DataFrame()\n",
    "\n",
    "    for i ∈ eachindex(x)\n",
    "        flow = x[i];\n",
    "        edgetuple = ei[i];\n",
    "\n",
    "        row_df = (\n",
    "            edge = i,\n",
    "            start = edgetuple[1],\n",
    "            stop = edgetuple[2],\n",
    "            flow = flow\n",
    "        );\n",
    "        push!(df, row_df);\n",
    "    end\n",
    "\n",
    "    pretty_table(df, tf=tf_simple)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4323a271-9d4e-408a-8441-0b07617aa17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert sum(x) ≈ model.τ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3410d177-71af-40e1-8c47-04c57c59a6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×6 Matrix{Float64}:\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233f9069-ca98-4e56-8a72-f9c34a3b2c95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
