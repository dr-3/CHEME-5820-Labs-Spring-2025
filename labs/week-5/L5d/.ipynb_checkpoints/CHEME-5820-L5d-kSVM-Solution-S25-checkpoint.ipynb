{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32fe3c6d-09ea-4c0e-81f7-3c8454d05e77",
   "metadata": {},
   "source": [
    "# L5d: Kernelized Support Vector Machines (kSVMs)\n",
    "In this lab, we will experiment with a kernel Support Vector Machine (kSVM) to classify the non-linearly separable datasets we construct. In particular, we'll look at a kernelized version of the soft-margin support vector machine. If these terms are unfamiliar, [check out the L5c notes](https://github.com/varnerlab/CHEME-5820-Lectures-Spring-2025/blob/main/lectures/week-5/L5c/docs/Notes.pdf) and the review below.\n",
    "\n",
    "### Theory: Support Vector Machine (SVM)\n",
    "Suppose, we have dataset $\\mathcal{D} = \\{(\\hat{\\mathbf{x}}_{i}, y_{i}) \\mid i = 1,2,\\dots,n\\}$, where $\\hat{\\mathbf{x}}_i \\in \\mathbb{R}^p$ is an _augmented_ feature vector ($m$ features with additional `1` to model the bias on the end of the vector) and $y_i \\in \\{-1, 1\\}$ is the corresponding class label. The goal of an SVM (for binary classification tasks) is to find the hyperplane $\\mathcal{H}(\\hat{\\mathbf{x}}) = \\{\\hat{\\mathbf{x}} \\mid \\left<\\hat{\\mathbf{x}},\\theta\\right> = 0\\}$ that separates the data points into two classes (those points above the hyperplane, and those points below the hyperplane), where $\\theta \\in \\mathbb{R}^{p}$ ($p=m+1$) is the normal vector to the hyperplane, or the parameters of the model that we need to estimate.\n",
    "* __Why another method__? Support vector machines (SVMs) and other approaches, e.g., [the perceptron](https://en.wikipedia.org/wiki/Perceptron) differ primarily in their optimization objectives and training methods: while a [perceptron](https://en.wikipedia.org/wiki/Perceptron) can find _a hyperplane_ that separates classes, SVMs seek to find the _best hyperplane_ in the sense that the _margin_ between classes is maximized.\n",
    "\n",
    "#### Soft margin\n",
    "Let's take a look at a [schematic of the ideas behind a soft margin support vector machine](https://github.com/varnerlab/CHEME-5820-Lectures-Spring-2025/blob/main/lectures/week-5/L5c/docs/figs/Fig-SVM-Schematic-Softmargin.pdf).\n",
    "If the data is _not linearly separable_, then we know that a perfect $\\mathcal{H}(\\hat{\\mathbf{x}})$ will not exist, i.e., \n",
    "no hyperplane will separate the data without making at least one mistake. In this case, we can estimate the _best_ hyperplane possible by solving the maximum soft margin problem given by:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\min_{\\theta}\\quad & \\frac{1}{2}\\lVert{\\theta}\\rVert_{2}^{2} + C\\sum_{i=1}^{n}\\xi_{i}\\\\\n",
    "    \\text{subject to}\\quad & y_{i}\\left<\\hat{\\mathbf{x}}_{i},\\theta\\right> \\geq 1 - \\xi_{i}\\quad\\forall i\\\\\n",
    "    & \\xi_{i} \\geq 0\\quad\\forall i\n",
    "\\end{align*}\n",
    "$$\n",
    "where $\\xi_{i}$ is a _slack variable_, that quantifies the cost of a classification mistake, and $C>{0}$ is a user-adjustable parameter that controls the trade-off between maximizing the margin and minimizing the slack variables.\n",
    "* __Values of $C$__: If $C\\gg{1}$ the classifier will behave like the maximum (hard) margin classifier, i.e., mistakes will be expensive, and the search will avoid making choices with mistakes. However, if $C\\ll{1}$, the classifier will allow more slack (mistakes), i.e., mistakes are cheap, so what's it matter!\n",
    "\n",
    "### Tasks\n",
    "Before we start, divide into teams and familiarize yourself with the lab. Then, execute the `Run All Cells` command to check if you (or your neighbor) have any code or setup issues. Code issues, then raise your hands - and let's get those fixed!\n",
    "\n",
    "* __Task 1: Setup, Data, Constants (10 min)__: Let's take 10 minutes to explore how we will generate the datasets we'll explore today. We'll work through how to generate linearly separable and non-linearly separable datasets.\n",
    "* __Task 2: Linear SVM classification (15 min)__: In this task, we [use the SVM implementation exported by the `LIBSVM.jl` package](https://github.com/JuliaML/LIBSVM.jl) to classify the dataset $\\mathcal{D}$ generated in task 1 using a `linear kernel`. In particular, we use the `training` dataset to estimate the unknown model parameters $\\theta$ [using the `svmtrain(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl), and the `test` data to evaluate the performance of the classifier on unseen data [using the `svmpredict(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl).\n",
    "* __Task 3: Implement a Grid Search to estimate the optimal hyperparameters for an RBF-SVM (15 min)__: In this task, we'll perform a grid search to estimate the best hyperparameters for a keneralized SVM using the RBF kernel. We'll estimate the best $C$ parameter in the objective function and the length-scale $\\gamma$ parameter.\n",
    "\n",
    "Let's get going!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ef21be-0201-4515-89bb-ba8112541d8e",
   "metadata": {},
   "source": [
    "## Task 1: Setup, Data, and Prerequisites\n",
    "We set up the computational environment by including the `Include.jl` file, loading any needed resources, such as sample datasets, and setting up any required constants. \n",
    "* The `Include.jl` file also loads external packages, various functions that we will use in the exercise, and custom types to model the components of our problem. It checks for a `Manifest.toml` file; if it finds one, packages are loaded. Other packages are downloaded and then loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "070be284-e10c-4c83-90bb-4cab39d97ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be56e42-f2dd-4da0-a8df-b1bae63621eb",
   "metadata": {},
   "source": [
    "### Data\n",
    "In this section, we will build sample (binary) datasets $\\mathcal{D} = \\{(\\hat{\\mathbf{x}}_{i}, y_{i}) \\mid i = 1,2,\\dots,n\\}$ to classify. Before we get started, we specify some constants that we use later:\n",
    "* The `number_of_points_per_label::Int` variable controls the number of sample points in the dataset for each label. The total number of instances in $\\mathcal{D}$ will be two times this number.\n",
    "* The `number_of_training_examples::Int` variable controls the number of points we use for `training`, with the balance of the instances then going to `test`.\n",
    "* The `number_of_features::Int` variable controls the number of features in the data, i.e., for $\\mathbf{x}\\in\\mathbb{R}^{m}$, this value is `m`.\n",
    "* The `ϵ::Float64` variable is a threshold value for including a not linearly separable data point into the dataset $\\mathcal{D}$, i.e., it is the probability that if we generate data that is not separable, we include it in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb75e970-d8fd-467e-8793-4122fce566ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_points_per_label = 1000; # this should be 1000; number of samples per label (2 x this is the total)\n",
    "number_of_training_examples = 1600; # pick this many training examples at random\n",
    "number_of_features = 5; # we have this many features\n",
    "ϵ = 0.15; # threshold of random NLS points to accept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542a6e99-99b0-44c6-9266-8c473960f782",
   "metadata": {},
   "source": [
    "Let's set up the color dictionary to visualize the classification datasets. The keys of the `my_color_dictionary::Dict Int64, RGB` dictionary class labels, i.e., $ y\\in\\{-1,1\\}$ while the values are the colors mapped to that label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8bf8d35-4f28-448e-aa49-4fa6ae812b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_color_dictionary = Dict{Int64,RGB}();\n",
    "my_color_dictionary[1] = colorant\"#03045e\"; # color for Label = 1\n",
    "my_color_dictionary[-1] = colorant\"#e36414\"; # color for Label = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668d9e68-3fde-4b32-bf85-b34be4f508d3",
   "metadata": {},
   "source": [
    "Next, let's write a code to generate a [non-lineraly separable data set](https://en.wikipedia.org/wiki/Linear_separability) $\\mathcal{D}$ that we'll use to train (and test) our [kSVM](https://en.wikipedia.org/wiki/Support_vector_machine#Nonlinear_kernels).\n",
    "\n",
    "* First, we generate a random parameter vector $\\theta\\in\\mathbb{R}^{p}$ where $p = m+1$.\n",
    "* Next, we generate (random) augmented feature vecotors $\\hat{\\mathbf{x}}\\in\\mathbb{R}^{p}$ and for specified labels, and check the $y\\cdot\\left(\\hat{\\mathbf{x}}^{\\top}\\mathbf{\\theta}\\right) \\geq 0$ condition. If this condition is true, we `accept` that data; otherwise, we `reject` the data. If we `accept` the data, we store it in the `dataset` variable, a [Set](https://docs.julialang.org/en/v1/base/collections/#Base.Set) holding a [NamedTuple type](https://docs.julialang.org/en/v1/base/base/#Core.NamedTuple), which is a mix of a tuple and a dictionary. If we `reject` the data, we roll a random number and compare it to the `ϵ::Float64` threshold value. If the random number is less than or equal to `ϵ::Float64`, we keep the rejected sample (and add it to the sample archive).\n",
    "* We keep iterating the loop until the number of elements of the `dataset` is greater than or equal to the desired number of test points specified in the `number_of_points_per_label` variable.\n",
    "\n",
    "We return the dataset $\\mathcal{D}$ in the `D::Array{Float64,2}` array, where each row is an example, each column is a feature, except for the last column, which is the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4099b294-ce46-414c-98b4-69ea85e3743a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000×6 Matrix{Float64}:\n",
       " -0.17606     0.391149     1.98101      -0.939605   -1.07626   -1.0\n",
       " -0.382646    1.66003      1.76318      -1.48047     0.570419   1.0\n",
       "  0.286501   -0.642023    -0.581163     -1.00344     0.814704  -1.0\n",
       " -1.04071     0.198672     0.0267136     0.125014   -1.2436     1.0\n",
       " -0.751844    1.11528      0.905018     -0.89976    -0.181229   1.0\n",
       " -0.574957    0.727597    -0.630866     -1.98359    -0.942239  -1.0\n",
       " -1.07505     1.91519     -0.258865     -1.25058    -0.624554  -1.0\n",
       " -0.20326    -0.684101     1.76014      -0.718469   -1.17793    1.0\n",
       "  0.981547    1.27572     -1.10454       2.1299     -2.02522   -1.0\n",
       " -1.29308    -2.19791      1.24028       0.476583   -0.6499     1.0\n",
       "  0.621947   -0.422448     0.409316      0.0631877   1.46171   -1.0\n",
       "  0.244529   -1.00072     -0.184246     -1.52573    -2.45254   -1.0\n",
       " -0.786349    0.477384     1.48676      -0.707862   -0.907927  -1.0\n",
       "  ⋮                                                             ⋮\n",
       " -0.188172    0.493469    -0.000476776  -1.31123     2.3089    -1.0\n",
       " -1.7116      0.0790269   -1.66937      -0.883238   -0.726686   1.0\n",
       "  0.563872   -0.00713285  -0.108908     -1.49139    -1.16815   -1.0\n",
       " -0.316187    0.285566    -0.756183      0.506866    0.762023   1.0\n",
       " -2.4649      0.129154    -0.325649     -0.128308   -1.17836   -1.0\n",
       " -1.25756     0.160086     0.708295     -0.848135   -1.15275   -1.0\n",
       " -0.522165    1.68895      0.221719     -0.289751   -0.854298  -1.0\n",
       " -0.671596    2.32028     -1.21355       1.16842     2.16197    1.0\n",
       "  0.236909   -0.139572    -0.397804      1.0432      0.764501   1.0\n",
       "  0.169937    0.0501561    0.480437     -0.391997   -0.941286   1.0\n",
       " -0.0795541   1.25645      2.24933      -0.577377    1.37204    1.0\n",
       "  0.568189    0.529261    -0.698571      0.55222     0.424915   1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = let\n",
    "\n",
    "    # initialize \n",
    "    dataset = Set{@NamedTuple{x::Array{Float64,1},y::Int64}}();\n",
    "    w = randn(number_of_features+1); # tmp parameters that we use to make data\n",
    "\n",
    "    # Logic to generate y = 1 samples\n",
    "    should_keep_looping = true;\n",
    "    y = 1; # label for this section\n",
    "    while (should_keep_looping == true)\n",
    "        x = randn(number_of_features) |> x -> push!(x,1); # generate a random augmented feature vector\n",
    "        \n",
    "        # check -\n",
    "        if (y*(sum(w.*x)) ≥ 0.0)\n",
    "            data = (x = x, y = y); # use a tuple, and set to enforce unique\n",
    "            push!(dataset,data);\n",
    "        else\n",
    "            # failed!, Hmmmm. Should we keep this data??\n",
    "            if (rand() ≤ ϵ)\n",
    "                data = (x = x, y = y); # use a tuple, and set to enforce unique\n",
    "                push!(dataset,data);\n",
    "            end\n",
    "        end\n",
    "    \n",
    "        # if we have enough examples, stop iterating\n",
    "        if (length(dataset) >= number_of_points_per_label)\n",
    "            should_keep_looping = false\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Logic to generate y = -1 samples\n",
    "    should_keep_looping = true;\n",
    "    y = -1; # label for this section\n",
    "    while (should_keep_looping == true)\n",
    "        x = randn(number_of_features) |> x -> push!(x,1); # generate a random augmented feature vector\n",
    "        \n",
    "        # check -\n",
    "        if (y*(sum(w.*x)) ≥ 0.0) # this is a LS point, keep\n",
    "            data = (x = x, y = y); # use a tuple, and set to enforce unique\n",
    "            push!(dataset,data);\n",
    "        else\n",
    "            # failed!, Hmmmm. Should we keep this data??\n",
    "            if (rand() ≤ ϵ)\n",
    "                data = (x = x, y = y); # use a tuple, and set to enforce unique\n",
    "                push!(dataset,data);\n",
    "            end\n",
    "        end\n",
    "    \n",
    "        # If we have enough examples, stop iterating\n",
    "        if (length(dataset) >= 2*number_of_points_per_label)\n",
    "            should_keep_looping = false\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # ok, so let's put this data into a matrix -\n",
    "    D = Array{Float64,2}(undef, 2*number_of_points_per_label, number_of_features+1);\n",
    "    for i ∈ 1:2*number_of_points_per_label\n",
    "        example = pop!(dataset);\n",
    "        feature = example.x;\n",
    "        label = example.y;\n",
    "        for j ∈ 1:number_of_features\n",
    "            D[i,j] = feature[j];\n",
    "        end\n",
    "        D[i,end] = label;\n",
    "    end\n",
    "    D\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263a91da-873b-4d35-b339-4848d555c236",
   "metadata": {},
   "source": [
    "### Visualize dataset `D`\n",
    "`Unhide` the code block below to see how we plotted the dataset `D`, which contains two continuous features and a label. The color indicates the label.\n",
    "* __Summary__: We will get a different pattern of $\\pm{1}$ labels depending the `ϵ::Float64` value. The dark blue dots represent label `1`, while the orange data represents label `1`. Our classifier should be able to learn the mapping between the features and the labels for linearly separable datasets but may struggle with random outlier points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7302bcbf-7bce-4d74-9619-5889a0ca8af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mVisualization disabled for more than 2 features!\n"
     ]
    }
   ],
   "source": [
    "let\n",
    "\n",
    "    dataset = D; # what dataset am I looking at?\n",
    "    number_of_points_to_plot = size(dataset,1);\n",
    "    if (number_of_features > 2)\n",
    "        @info \"Visualization disabled for more than 2 features!\"\n",
    "    else\n",
    "        p = plot(bg=\"gray95\", background_color_outside=\"white\", framestyle = :box, fg_legend = :transparent); # make an empty plot\n",
    "    \n",
    "        # plot label = 1\n",
    "        testlabel = 1;\n",
    "        i = findfirst(label -> label == testlabel,  dataset[:,3])\n",
    "        c = my_color_dictionary[testlabel]\n",
    "        scatter!([dataset[i,1]], [dataset[i,2]], label=\"Label: $(testlabel)\", c=c)\n",
    "    \n",
    "        # plot label = -1\n",
    "        testlabel = -1;\n",
    "        i = findfirst(label -> label == testlabel,  dataset[:,3])\n",
    "        c = my_color_dictionary[testlabel]\n",
    "        scatter!([dataset[i,1]], [dataset[i,2]], label=\"Label: $(testlabel)\", c=c)\n",
    "    \n",
    "        # plot all points\n",
    "        for i ∈ 1:number_of_points_to_plot\n",
    "            label = dataset[i,3]; # label\n",
    "            c = my_color_dictionary[label]\n",
    "            scatter!([dataset[i, 1]], [dataset[i, 2]], label=\"\", mec=:navy, c=c)\n",
    "        end\n",
    "        \n",
    "        xlabel!(\"Feature 1 (AU)\", fontsize=18);\n",
    "        ylabel!(\"Feature 2 (AU)\", fontsize=18);\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fa2adc-4611-442e-8d59-815186227901",
   "metadata": {},
   "source": [
    "Next, let's split that dataset `D` into `training` and `test` subsets. We do this randomly, where the `number_of_training_examples::Int64` variable specifies the number of training points. The `training::Array{Float64,2}` data will be used to estimate the model parameters, and `test::Array{Float64,2}` will be used for model testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a138b06c-0106-4e55-b68e-bdd561076c64",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ParseError:\n\u001b[90m# Error @ \u001b[0;0m\u001b]8;;file:///Users/jeffreyvarner/Desktop/julia_work/CHEME-5820-SP25/CHEME-5820-Labs-Spring-2025/labs/week-5/L5d/In[13]#1:1\u001b\\\u001b[90mIn[13]:1:1\u001b[0;0m\u001b]8;;\u001b\\\n\u001b[48;2;120;70;70m,\u001b[0;0m test = let\n\u001b[90m╙ ── \u001b[0;0m\u001b[91munexpected `,`\u001b[0;0m",
     "output_type": "error",
     "traceback": [
      "ParseError:\n\u001b[90m# Error @ \u001b[0;0m\u001b]8;;file:///Users/jeffreyvarner/Desktop/julia_work/CHEME-5820-SP25/CHEME-5820-Labs-Spring-2025/labs/week-5/L5d/In[13]#1:1\u001b\\\u001b[90mIn[13]:1:1\u001b[0;0m\u001b]8;;\u001b\\\n\u001b[48;2;120;70;70m,\u001b[0;0m test = let\n\u001b[90m╙ ── \u001b[0;0m\u001b[91munexpected `,`\u001b[0;0m",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[13]:1"
     ]
    }
   ],
   "source": [
    "training, test = let\n",
    "\n",
    "    number_of_features = size(D,2); # number of cols of housing data\n",
    "    number_of_examples = size(D,1); # number of rows of housing data\n",
    "    full_index_set = range(1,stop=number_of_examples,step=1) |> collect |> Set;\n",
    "    \n",
    "    # build index sets for training and testing\n",
    "    training_index_set = Set{Int64}();\n",
    "    should_stop_loop = false;\n",
    "    while (should_stop_loop == false)\n",
    "        i = rand(1:number_of_examples);\n",
    "        push!(training_index_set,i);\n",
    "\n",
    "        if (length(training_index_set) == number_of_training_examples)\n",
    "            should_stop_loop = true;\n",
    "        end\n",
    "    end\n",
    "    test_index_set = setdiff(full_index_set,training_index_set);\n",
    "\n",
    "    # build the test and train datasets -\n",
    "    training = D[training_index_set |> collect,:];\n",
    "    test = D[test_index_set |> collect,:];\n",
    "\n",
    "    # return\n",
    "    training, test\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76e1edb9-34f8-484b-bbaa-cfbac629c6ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `test` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nHint: a global variable of this name also exists in Pkg.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `test` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nHint: a global variable of this name also exists in Pkg.",
      ""
     ]
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383ff19e-5964-4fc5-90c8-0f0577ba06bc",
   "metadata": {},
   "source": [
    "## Task 2: Classification using an Linear SVM\n",
    "In this task, we [use the SVM implementation exported by the `LIBSVM.jl` package](https://github.com/JuliaML/LIBSVM.jl) to classify the dataset $\\mathcal{D}$ generated in task 1 using a `linear kernel`. In particular, we use the `training` dataset to estimate the unknown model parameters $\\theta$ [using the `svmtrain(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl), and the `test` data to evaluate the performance of the classifier on unseen data [using the `svmpredict(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl). \n",
    "* The [`svmtrain(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl) takes an augmented training examples matrix $\\hat{\\mathbf{X}}^{\\top}$ where the examples are on the columns and the features are the rows, and a label vector $\\mathbf{y}\\in\\left\\{-1,1\\right\\}$.\n",
    "* The [`svmtrain(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl) returns a [model instance](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl) that holds the trained data and a bunch of other data associated with the problem.\n",
    "* __Hmmm__: One of the (super) interesting optional arguments [the `svmtrain(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl) is the `kernel` argument. Check out the documentation to see what kernels are supported! Wow! we get [kernelized SVM capability](https://en.wikipedia.org/wiki/Support_vector_machine#Nonlinear_kernels) right out of the box. _Buy versus build, 99% buy!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9c5e427-8dce-47b2-a1d3-51fd7bcfbbed",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[16]:4"
     ]
    }
   ],
   "source": [
    "model = let\n",
    "\n",
    "    # Setup the data that we are using\n",
    "    D = training; # what dataset are we looking at?\n",
    "    number_of_examples = size(D,1); # how many rows?\n",
    "    X = [D[:,1:end-1] ones(number_of_examples)] |> transpose |> Matrix; # augmented features (arranged as m x n)\n",
    "    y = D[:,end]; # label\n",
    "\n",
    "    # TODO: Uncomment the line below to train the SVM model using the training data \n",
    "    model = svmtrain(X, y, kernel=LIBSVM.Kernel.Linear, verbose = true); # we are using the LIBSVM\n",
    "\n",
    "    # return\n",
    "    model\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dc7cc9b-5cd0-46ab-9c9f-d220b48a4677",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `model` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `model` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      ""
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a40341-4c8c-4511-8a6f-814182d10735",
   "metadata": {},
   "source": [
    "__Inference__: Now that we have parameters estimated from the `training` data, we can use those parameters on the `test` dataset to see how well the model can differentiate between an actual banknote and a forgery on data it has never seen. We run the classification operation on the (unseen) test data [using the `svmpredict(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl). \n",
    "* The [`svmpredict(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl) returns the predicted label which we store in the `ŷ::Array{Int64,1}` array. We store the actual (correct) label in the `y::Array{Int64,1}` vector.\n",
    "* The [`svmpredict(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl) also returns a second output which we save in the `decision_values` variable. __Hmmmm__. Not sure what these values are ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b42d7969-9bfa-4f4f-98fb-ea9443c11eab",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `test` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nHint: a global variable of this name also exists in Pkg.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `test` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nHint: a global variable of this name also exists in Pkg.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[19]:4"
     ]
    }
   ],
   "source": [
    "ŷ,y,d = let\n",
    "\n",
    "     # Setup the data that we are using\n",
    "    D = test; # what dataset are we looking at?\n",
    "    number_of_examples = size(D,1); # how many rows?\n",
    "    X = [D[:,1:end-1] ones(number_of_examples)] |> transpose |> Matrix; # features (arranged as m x n)\n",
    "    y = D[:,end]; # label\n",
    "    \n",
    "    # TODO: Uncomment the line below to test the SVM model on the other block of the data.\n",
    "    ŷ, decision_values = svmpredict(model, X);\n",
    "\n",
    "    # return -\n",
    "    ŷ,y,decision_values\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efea4db2-103c-4e8f-b858-96dd1fb66db5",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "Finally, let's compute the confusion matrix. The confusion matrix is a $2\\times{2}$ matrix that contains four entries: true positive (TP), false positive (FP), true negative (TN), and false negative (FN). [Click me for a confusion matrix schematic!](https://github.com/varnerlab/CHEME-5820-Labs-Spring-2025/blob/main/labs/week-3/L3b/figs/Fig-BinaryConfusionMatrix.pdf). Let's compute these four values [using the `confusion(...)` method](src/Compute.jl) and store them in the `CM::Array{Int64,2}` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d57ea7ec-1fd8-41cf-9d4d-e85768e10d37",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `y` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `y` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[21]:1"
     ]
    }
   ],
   "source": [
    "CM = confusion(y, ŷ) # call with the SVM test values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52750870-9c80-4e72-8dfa-6761ba710171",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `y` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `y` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[22]:1"
     ]
    }
   ],
   "source": [
    "number_of_test_points = length(y);\n",
    "correct_prediction_perceptron = CM[1,1] + CM[2,2];\n",
    "(correct_prediction_perceptron/number_of_test_points) |> f-> println(\"Fraction correct: $(f) Fraction incorrect $(1-f)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a9218-6a6a-4ca4-b6c1-e107d8e2d083",
   "metadata": {},
   "source": [
    "### DQs \n",
    "Before we move to task 3, let's explore a few issues. [This may be handy](https://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf) or [maybe this?](https://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf)\n",
    "1. Are we solving the `hard` or the `soft` margin problem?\n",
    "2. What are all the fields inside the `model` instance, and what do they mean? Let's [check out the code, and see what we see!](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl)\n",
    "3. What are the `decision_values` that are returned from the [`svmpredict(...)` method](https://github.com/JuliaML/LIBSVM.jl/blob/master/src/LIBSVM.jl) (we saved these in the `d` variable)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbfd488a-746f-45d8-891c-5b4696d490bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `d` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `d` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      ""
     ]
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0e2021-5686-473e-8f6b-a4508bb14a31",
   "metadata": {},
   "source": [
    "## Task 3: Implement a Grid Search to estimate the optimal hyperparameters for an RBF-SVM\n",
    "In this task, we'll perform a grid search to estimate the best hyperparameters for a keneralized SVM using the RBF kernel. We'll estimate the best $C$ parameter in the objective function and the length-scale $\\gamma$ parameter.\n",
    "\n",
    "[A grid search](https://en.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search) for kernel SVM parameters C and $\\gamma$ involves systematically exploring combinations of these hyperparameters to find the optimal configuration for model performance. Here's a description of the process:\n",
    "* __Define parameter ranges__. For the cost parameter $C$, we use $C\\in\\left\\{2^{-5},2^{-3},\\dots,2^{15}\\right\\}$ while for the length scale parameter $\\gamma$, we use $\\gamma\\in\\left\\{2^{-15},2^{-13},\\dots,2^{3}\\right\\}$. We store the exponents of these ranges in the `α::Array{Float64,1}` and `β::Array{Float64,1}` arrays, respectively.\n",
    "* __Model training and evaluation__: For each parameter combination $(C_{i},\\gamma_{j})$ we train a SVM model with a RBF kernel, compute the confusion matrix and then evaluate the prediction accuracy. We save the accuracy data in the `A::Array{Float64,2}` array, where $a_{ij}\\in\\mathbf{A}$ holds the accuracy values for the parameter combination $(C_{i},\\gamma_{j})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "916a6ac0-a18f-4b0e-9aa5-dda1e0fa7dd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[26]:4"
     ]
    }
   ],
   "source": [
    "A, α, β = let\n",
    "\n",
    "    # Training data setup -\n",
    "    D₁ = training; # what dataset are we looking at?\n",
    "    number_of_training_examples = size(D₁,1); # how many rows?\n",
    "    X₁ = [D₁[:,1:end-1] ones(number_of_training_examples)] |> transpose |> Matrix; # augmented features (arranged as m x n)\n",
    "    y₁ = D₁[:,end]; # label\n",
    "\n",
    "    # Test data setup -\n",
    "    D₂ = test; # what dataset are we looking at?\n",
    "    number_of_test_examples = size(D₂,1); # how many rows?\n",
    "    X₂ = [D₂[:,1:end-1] ones(number_of_test_examples)] |> transpose |> Matrix; # features (arranged as m x n)\n",
    "    y₂ = D₂[:,end]; # label\n",
    "    \n",
    "    α = range(-5,stop = 15, step=2) |> collect; # exponent for C -\n",
    "    β = range(-15,stop = 3, step=2) |> collect; # exponent for γ -\n",
    "    number_of_points_C = length(α);\n",
    "    number_of_points_gamma = length(β);\n",
    "    accuracy = Array{Float64,2}(undef, number_of_points_C, number_of_points_gamma);\n",
    "    \n",
    "    for i ∈ eachindex(α)\n",
    "        C = 2.0^α[i];\n",
    "        for j ∈ eachindex(β)\n",
    "            γ = 2.0^β[j];\n",
    "\n",
    "            # TODO: Uncomment below to train the mode in the (C,γ) values -\n",
    "            ŷ₂,_ = svmtrain(X₁, y₁, kernel=LIBSVM.Kernel.RadialBasis, \n",
    "                verbose = false, cost = C, gamma = γ) |> model -> svmpredict(model,X₂);\n",
    "\n",
    "            # how many mistakes?\n",
    "            accuracy[i,j] = confusion(y₂, ŷ₂) |> CM -> CM[1,1] + CM[2,2] |> correct -> correct/number_of_test_examples;\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    accuracy, α, β\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfccd256-16f9-4a9f-a649-f25f161fdb53",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `A` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `A` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[27]:1"
     ]
    }
   ],
   "source": [
    "Gray.(1 .- A) # fun! More accurate parameter combinations are darker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "476dbf34-3f9d-482e-a389-46b0325d6872",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `A` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `A` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      ""
     ]
    }
   ],
   "source": [
    "A # rows are C, cols are γ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb00c9e8-1f2c-4e93-b766-cd6b634ae35d",
   "metadata": {},
   "source": [
    "### What is the best SVM model?\n",
    "Let's find the model with the highest training accuracy. We'll call this the _best model_ and save it in the `best_model::LIBSVM.SVM` variable. First, which element of the accuracy matrix $\\mathbf{A}$ holds the maximum?\n",
    "* We can estimate maximum accuracy element of the matrix $\\mathbf{A}$ [using the `maximum(...)` method](https://docs.julialang.org/en/v1/base/collections/#Base.maximum). The `(i,j)` position of the maximum element can be computed using [the `argmax(...)` method](https://docs.julialang.org/en/v1/base/collections/#Base.argmax). The [`argmax(...)` method](https://docs.julialang.org/en/v1/base/collections/#Base.argmax) returns a cool data structure [called a `CartesianIndex`](https://docs.julialang.org/en/v1/base/arrays/#Base.IteratorsMD.CartesianIndex) which holds the (`row, col`) values of the maximum. This data structure is a way to model collection indices (which seems interesting!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b7cb67f-dcaa-4fcd-a800-389d8b580625",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `A` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `A` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[30]:1"
     ]
    }
   ],
   "source": [
    "coordinate = argmax(A)\n",
    "best_accuracy = maximum(A)\n",
    "println(\"Best test accuracy: $(best_accuracy)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b1269ae-8a2f-4720-8b23-d96b06198aec",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `coordinate` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `coordinate` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      ""
     ]
    }
   ],
   "source": [
    "coordinate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25f19ea-d180-491e-bde0-6092861dac79",
   "metadata": {},
   "source": [
    "Next, get the best parameters, and save these in the `C_best::Float64` and `γ_best::Float64` variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab4c8dd4-b872-413b-852c-4f0e578bdfa5",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `coordinate` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `coordinate` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[33]:3"
     ]
    }
   ],
   "source": [
    "C_best, γ_best = let\n",
    "    \n",
    "    C = coordinate[1] |> i-> α[i] |> e-> 2.0^e; # Wow! we grab the row (corresponds to C), get the exponent from α, and then compute the value\n",
    "    γ = coordinate[2] |> i-> β[i] |> e-> 2.0^e; # Nice! grab the col (corresponds to γ), get the exponent from β, and then compute the value\n",
    "\n",
    "    C,γ\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1db671b-1b5a-4afb-990e-3ce8bd784158",
   "metadata": {},
   "source": [
    "Finally, estimate the `best_model::LIBSVM.SVM`, the best predicted label vector `ŷ_test_best::Array{Int64,1}`, and the actual label vector `y_test::Array{Int64,1}` using the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a16e8e86-49ee-41e9-b935-f8fce18f882e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `training` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[35]:4"
     ]
    }
   ],
   "source": [
    "best_model, ŷ_test_best, y_test = let\n",
    "\n",
    "    # Training data setup -\n",
    "    D₁ = training; # what dataset are we looking at?\n",
    "    number_of_training_examples = size(D₁,1); # how many rows?\n",
    "    X₁ = [D₁[:,1:end-1] ones(number_of_training_examples)] |> transpose |> Matrix; # augmented features (arranged as m x n)\n",
    "    y₁ = D₁[:,end]; # label\n",
    "\n",
    "    # Test data setup -\n",
    "    D₂ = test; # what dataset are we looking at?\n",
    "    number_of_test_examples = size(D₂,1); # how many rows?\n",
    "    X₂ = [D₂[:,1:end-1] ones(number_of_test_examples)] |> transpose |> Matrix; # features (arranged as m x n)\n",
    "    y₂ = D₂[:,end]; # label\n",
    "\n",
    "    # estimate the best model -\n",
    "    best_model = svmtrain(X₁, y₁, kernel=LIBSVM.Kernel.RadialBasis, \n",
    "                    verbose = false, cost = C_best, gamma = γ_best)\n",
    "    \n",
    "\n",
    "    # compute the ŷ_best -\n",
    "    ŷ_best, _ = svmpredict(best_model,X₂);\n",
    "\n",
    "    # return -\n",
    "    best_model, ŷ_best, y₂\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da36dd-5158-4179-92db-22685d733c49",
   "metadata": {},
   "source": [
    "Confirm the accuracy of the `best_model::LIBSVM.`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81cb4bb2-606f-466f-a8ca-bc03112e9202",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: `y_test` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `y_test` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[37]:1"
     ]
    }
   ],
   "source": [
    "accuracy_best_confirm = confusion(y_test, ŷ_test_best) |> CM -> CM[1,1] + CM[2,2] |> correct -> correct/size(test,1) # impressive!\n",
    "@assert best_accuracy == accuracy_best_confirm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3af624-e89b-4ff6-b8e5-e5c2a8e8c367",
   "metadata": {},
   "source": [
    "### DQs\n",
    "1. What factors influence the prediction accuracy of the kSVM? For example, do the number of features influence performance or the fraction of random points? Let's run a few cases with different parameters and develop some intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdee974d-d33b-473e-8d2a-088691db4dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
